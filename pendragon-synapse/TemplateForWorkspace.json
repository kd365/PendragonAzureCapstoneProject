{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "pendragon-synapse"
		},
		"AzureDataLakeStorage1_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'AzureDataLakeStorage1'"
		},
		"AzureSqlDatabase1_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'AzureSqlDatabase1'"
		},
		"AzureSqlDatabase2_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'AzureSqlDatabase2'"
		},
		"pendragon-synapse-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'pendragon-synapse-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:pendragon-synapse.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"AzureDataLakeStorage1_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://pendragon.dfs.core.windows.net/"
		},
		"AzureMLService1_properties_typeProperties_subscriptionId": {
			"type": "string",
			"defaultValue": "57cd2ff8-9306-41d0-9cad-c2052a0a8381"
		},
		"AzureMLService1_properties_typeProperties_resourceGroupName": {
			"type": "string",
			"defaultValue": "Spring2023-TeamPendragon"
		},
		"CognitiveService1_properties_typeProperties_subscriptionId": {
			"type": "string",
			"defaultValue": "57cd2ff8-9306-41d0-9cad-c2052a0a8381"
		},
		"PendragonKeyVault_properties_typeProperties_baseUrl": {
			"type": "string",
			"defaultValue": "https://pendragonkeys.vault.azure.net/"
		},
		"RestService_Next_Token_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://api.twitter.com"
		},
		"RestService_Twitter_7days_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://api.twitter.com"
		},
		"Twitter_RestService_ Aithusa_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://api.twitter.com"
		},
		"Twitter_RestService_AS_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://api.twitter.com"
		},
		"pendragon-synapse-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://pendragon.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/CognitiveServices')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Lookup1",
						"type": "Lookup",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "SqlPoolSource",
								"sqlReaderQuery": "SELECT TOP 10 id, lang, text FROM dbo.NATO_Tweets1;\n",
								"queryTimeout": "02:00:00"
							},
							"dataset": {
								"referenceName": "DedicatedSqlPoolTable1",
								"type": "DatasetReference",
								"parameters": {}
							},
							"firstRowOnly": false
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Lookup1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Lookup1').output.value",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Web1",
									"type": "WebActivity",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"url": "https://pendragon-language.cognitiveservices.azure.com/language/:analyze-text?api-version=2022-05-01",
										"connectVia": {
											"referenceName": "AutoResolveIntegrationRuntime",
											"type": "IntegrationRuntimeReference"
										},
										"method": "POST",
										"headers": {
											"Content-Type": "application/json",
											"Ocp-Apim-Subscription-Key": "a3028b5f7e7a462d8a3381e49b9c976d"
										},
										"body": {
											"value": "@'\n{\n    \"kind\": \"KeyPhraseExtraction\",\n    \"parameters\": {\n        \"modelVersion\": \"latest\"\n    },\n    \"analysisInput\":{\n        \"documents\":[\n            {\n                \"language\": \"en\", \"id\": \"',\n                    item().id,\n                    '\", \"text\": \"' , item().text ,'\"\n            }\n        ]\n    }\n}\n'",
											"type": "Expression"
										}
									}
								},
								{
									"name": "Append variable1",
									"type": "AppendVariable",
									"dependsOn": [
										{
											"activity": "Web1",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"variableName": "KeyPhrases",
										"value": {
											"value": "@activity('Web1').output.results.documents[0].keyPhrases[0]",
											"type": "Expression"
										}
									}
								}
							]
						}
					},
					{
						"name": "ForEach2",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Lookup1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Lookup1').output.value",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Append variable2",
									"type": "AppendVariable",
									"dependsOn": [],
									"userProperties": [],
									"typeProperties": {
										"variableName": "text",
										"value": {
											"value": "@item().text",
											"type": "Expression"
										}
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"KeyPhrases": {
						"type": "Array"
					},
					"text": {
						"type": "Array"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/DedicatedSqlPoolTable1')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GET Loop Next Token RT')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Initial GET Past 7 Days",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Delete Previous Output Files",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Delete Previous Merged Output files",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "RestSource",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": "00.00:00:00.010",
								"requestMethod": "GET",
								"paginationRules": {
									"supportRFC5988": "true"
								}
							},
							"sink": {
								"type": "JsonSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "JsonWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "RestResourceTwitter7days",
								"type": "DatasetReference",
								"parameters": {
									"query": {
										"value": "@variables('Query')",
										"type": "Expression"
									},
									"tweet_fields": {
										"value": "@variables('Tweet Fields')",
										"type": "Expression"
									},
									"max_results": {
										"value": "@variables('max_results')",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Twitter_RawJSON_Temp",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "GET using Next Token",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Initial GET Past 7 Days",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Number of Loops",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@range(0,int(variables('loops')))",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Extract Next Token",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "Get Next Token",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"source1": {},
												"source2": {},
												"sink1": {},
												"sink2": {}
											}
										},
										"staging": {},
										"integrationRuntime": {
											"referenceName": "WarmIntegrationRuntime",
											"type": "IntegrationRuntimeReference"
										},
										"traceLevel": "None",
										"cacheSinks": {
											"firstRowOnly": true
										}
									}
								},
								{
									"name": "GET to Temp",
									"type": "Copy",
									"dependsOn": [
										{
											"activity": "Delete Temp File",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "RestSource",
											"httpRequestTimeout": "00:01:40",
											"requestInterval": "00.00:00:00.010",
											"requestMethod": "GET",
											"paginationRules": {
												"supportRFC5988": "true"
											}
										},
										"sink": {
											"type": "JsonSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "JsonWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "RestResource_Next_Token",
											"type": "DatasetReference",
											"parameters": {
												"query": {
													"value": "@variables('Query')",
													"type": "Expression"
												},
												"tweet_fields": {
													"value": "@variables('Tweet Fields')",
													"type": "Expression"
												},
												"max_results": {
													"value": "@variables('max_results')",
													"type": "Expression"
												},
												"next_token": {
													"value": "@activity('Extract Next Token').output.runStatus.output.sink1.value[0].next_token",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "Twitter_RawJSON_Temp",
											"type": "DatasetReference",
											"parameters": {}
										}
									]
								},
								{
									"name": "Delete Temp File",
									"type": "Delete",
									"dependsOn": [
										{
											"activity": "Extract Next Token",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "Twitter_RawJSON_Temp",
											"type": "DatasetReference",
											"parameters": {}
										},
										"enableLogging": false,
										"storeSettings": {
											"type": "AzureBlobFSReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										}
									}
								}
							]
						}
					},
					{
						"name": "Query",
						"type": "SetVariable",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"variableName": "Query",
							"value": "\"NATO\" lang:en -is:retweet -is:reply"
						}
					},
					{
						"name": "Max Results",
						"type": "SetVariable",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"variableName": "max_results",
							"value": "100"
						}
					},
					{
						"name": "Tweet Fields",
						"type": "SetVariable",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"variableName": "Tweet Fields",
							"value": "id,text,created_at,lang,public_metrics"
						}
					},
					{
						"name": "Delete Previous Output Files",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "Query",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Max Results",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Tweet Fields",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Raw_Twitter_Outputs",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Number of Loops",
						"type": "SetVariable",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"variableName": "loops",
							"value": "5"
						}
					},
					{
						"name": "Delete NATO Temp file",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "GET using Next Token",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Twitter_RawJSON_Temp",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Merge JSONs and Convert to CSV",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Delete NATO Temp file",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Merge JSON to CSV",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"integrationRuntime": {
								"referenceName": "WarmIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "Delete Previous Merged Output files",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "Query",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Merged_JSON_folder",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Copy data to Dedicated SQL Pool",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Delete All Existing Rows in NATO_Tweets1 Table",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"wildcardFileName": "*",
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "SqlPoolSink",
								"allowCopyCommand": true,
								"copyCommandSettings": {}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": "id",
											"type": "Int64"
										},
										"sink": {
											"name": "id",
											"type": "Int64"
										}
									},
									{
										"source": {
											"name": "created_at",
											"type": "DateTime"
										},
										"sink": {
											"name": "created_at",
											"type": "DateTime"
										}
									},
									{
										"source": {
											"name": "text",
											"type": "String"
										},
										"sink": {
											"name": "text",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "lang",
											"type": "String"
										},
										"sink": {
											"name": "lang",
											"type": "String"
										}
									},
									{
										"source": {
											"name": "retweet_count",
											"type": "Int32"
										},
										"sink": {
											"name": "retweet_count",
											"type": "Int32"
										}
									},
									{
										"source": {
											"name": "reply_count",
											"type": "Int32"
										},
										"sink": {
											"name": "reply_count",
											"type": "Int32"
										}
									},
									{
										"source": {
											"name": "like_count",
											"type": "Int32"
										},
										"sink": {
											"name": "like_count",
											"type": "Int32"
										}
									},
									{
										"source": {
											"name": "quote_count",
											"type": "Int32"
										},
										"sink": {
											"name": "quote_count",
											"type": "Int32"
										}
									},
									{
										"source": {
											"name": "impression_count",
											"type": "Int32"
										},
										"sink": {
											"name": "impression_count",
											"type": "Int32"
										}
									}
								]
							}
						},
						"inputs": [
							{
								"referenceName": "Merged_output_csv",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "DedicatedSqlPoolTable1",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Delete All Existing Rows in NATO_Tweets1 Table",
						"type": "SqlPoolStoredProcedure",
						"dependsOn": [
							{
								"activity": "Merge JSONs and Convert to CSV",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"sqlPool": {
							"referenceName": "SQLPoolTest",
							"type": "SqlPoolReference"
						},
						"typeProperties": {
							"storedProcedureName": "[dbo].[DeleteAllRowsFromNatoTweets1]"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"Query": {
						"type": "String"
					},
					"max_results": {
						"type": "String"
					},
					"Tweet Fields": {
						"type": "String"
					},
					"Number of Tweets to Pull": {
						"type": "String"
					},
					"loops": {
						"type": "String"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/RestResourceTwitter7days')]",
				"[concat(variables('workspaceId'), '/datasets/Twitter_RawJSON_Temp')]",
				"[concat(variables('workspaceId'), '/datasets/Raw_Twitter_Outputs')]",
				"[concat(variables('workspaceId'), '/dataflows/Merge JSON to CSV')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/WarmIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/datasets/Merged_JSON_folder')]",
				"[concat(variables('workspaceId'), '/datasets/Merged_output_csv')]",
				"[concat(variables('workspaceId'), '/datasets/DedicatedSqlPoolTable1')]",
				"[concat(variables('workspaceId'), '/sqlPools/SQLPoolTest')]",
				"[concat(variables('workspaceId'), '/dataflows/Get Next Token')]",
				"[concat(variables('workspaceId'), '/datasets/RestResource_Next_Token')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GET Until Next Token')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Query",
						"type": "SetVariable",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"variableName": "Query",
							"value": "\"NATO\" lang:en -is:retweet -is:reply"
						}
					},
					{
						"name": "Max Results",
						"type": "SetVariable",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"variableName": "max_results",
							"value": "100"
						}
					},
					{
						"name": "Tweet Fields",
						"type": "SetVariable",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"variableName": "Tweet Fields",
							"value": "id,text,created_at,lang,public_metrics"
						}
					},
					{
						"name": "Delete Previous Output Files",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "Query",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Max Results",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Tweet Fields",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Raw_Aithusa_Outputs",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Delete Previous Merged Output files",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "Query",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Merged_Aithusa_JSON_folder",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Until GET Tweets",
						"type": "Until",
						"dependsOn": [
							{
								"activity": "Set variable1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@equals(variables('stopUntil'), 'true')",
								"type": "Expression"
							},
							"activities": [
								{
									"name": "Extract Next Token Aithusa",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "Get Next Token for Aithusa",
											"type": "DataFlowReference",
											"parameters": {},
											"datasetParameters": {
												"source1": {},
												"source2": {},
												"sink1": {},
												"sink2": {}
											}
										},
										"staging": {},
										"integrationRuntime": {
											"referenceName": "WarmIntegrationRuntime",
											"type": "IntegrationRuntimeReference"
										},
										"traceLevel": "None",
										"cacheSinks": {
											"firstRowOnly": true
										}
									}
								},
								{
									"name": "Delete Temp File",
									"type": "Delete",
									"dependsOn": [
										{
											"activity": "Extract Next Token Aithusa",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "json_Aithusa",
											"type": "DatasetReference",
											"parameters": {}
										},
										"enableLogging": false,
										"storeSettings": {
											"type": "AzureBlobFSReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										}
									}
								},
								{
									"name": "If next_token null",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "If specific date with token",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@equals(activity('Extract Next Token Aithusa').output.runStatus.output.sink1.value[0].next_token, '\\n')",
											"type": "Expression"
										},
										"ifFalseActivities": [
											{
												"name": "Set stopUntil 1",
												"type": "SetVariable",
												"dependsOn": [],
												"userProperties": [],
												"typeProperties": {
													"variableName": "stopUntil",
													"value": "'false'"
												}
											}
										],
										"ifTrueActivities": [
											{
												"name": "Set stopUntil",
												"type": "SetVariable",
												"dependsOn": [],
												"userProperties": [],
												"typeProperties": {
													"variableName": "stopUntil",
													"value": "'true'"
												}
											}
										]
									}
								},
								{
									"name": "If specific date with token",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "Delete Temp File",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@bool(variables('specific_date'))",
											"type": "Expression"
										},
										"ifFalseActivities": [
											{
												"name": "GET Past 7 Days with token",
												"type": "Copy",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "RestSource",
														"httpRequestTimeout": "00:01:40",
														"requestInterval": "00.00:00:00.010",
														"requestMethod": "GET",
														"paginationRules": {
															"supportRFC5988": "true"
														}
													},
													"sink": {
														"type": "JsonSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings"
														},
														"formatSettings": {
															"type": "JsonWriteSettings"
														}
													},
													"enableStaging": false
												},
												"inputs": [
													{
														"referenceName": "RestResource_Aithusa_7days_NextToken",
														"type": "DatasetReference",
														"parameters": {
															"query": {
																"value": "@variables('Query')",
																"type": "Expression"
															},
															"tweet_fields": {
																"value": "@variables('Tweet Fields')",
																"type": "Expression"
															},
															"max_results": {
																"value": "@variables('max_results')",
																"type": "Expression"
															},
															"next_token": {
																"value": "@activity('Extract Next Token Aithusa').output.runStatus.output.sink1.value[0].next_token",
																"type": "Expression"
															}
														}
													}
												],
												"outputs": [
													{
														"referenceName": "json_Aithusa",
														"type": "DatasetReference",
														"parameters": {}
													}
												]
											}
										],
										"ifTrueActivities": [
											{
												"name": "GET with specifc date with token",
												"type": "Copy",
												"dependsOn": [],
												"policy": {
													"timeout": "0.12:00:00",
													"retry": 0,
													"retryIntervalInSeconds": 30,
													"secureOutput": false,
													"secureInput": false
												},
												"userProperties": [],
												"typeProperties": {
													"source": {
														"type": "RestSource",
														"httpRequestTimeout": "00:01:40",
														"requestInterval": "00.00:00:00.010",
														"requestMethod": "GET",
														"paginationRules": {
															"supportRFC5988": "true"
														}
													},
													"sink": {
														"type": "JsonSink",
														"storeSettings": {
															"type": "AzureBlobFSWriteSettings"
														},
														"formatSettings": {
															"type": "JsonWriteSettings"
														}
													},
													"enableStaging": false
												},
												"inputs": [
													{
														"referenceName": "RestResource_Aithusa_withToken",
														"type": "DatasetReference",
														"parameters": {
															"Query": {
																"value": "@variables('Query')",
																"type": "Expression"
															},
															"max_results": {
																"value": "@variables('max_results')",
																"type": "Expression"
															},
															"tweet_fields": {
																"value": "@variables('Tweet Fields')",
																"type": "Expression"
															},
															"start_year": {
																"value": "@variables('start_year')",
																"type": "Expression"
															},
															"start_month": {
																"value": "@variables('start_month')",
																"type": "Expression"
															},
															"start_day": {
																"value": "@variables('start_day')",
																"type": "Expression"
															},
															"start_hour": {
																"value": "@variables('start_hour')",
																"type": "Expression"
															},
															"start_minute": {
																"value": "@variables('start_minute')",
																"type": "Expression"
															},
															"start_second": "00",
															"end_year": {
																"value": "@variables('end_year')",
																"type": "Expression"
															},
															"end_month": {
																"value": "@variables('end_month')",
																"type": "Expression"
															},
															"end_day": {
																"value": "@variables('end_day')",
																"type": "Expression"
															},
															"end_hour": {
																"value": "@variables('end_hour')",
																"type": "Expression"
															},
															"end_minute": {
																"value": "@variables('end_minute')",
																"type": "Expression"
															},
															"end_second": "00",
															"next_token": {
																"value": "@activity('Extract Next Token Aithusa').output.runStatus.output.sink1.value[0].next_token",
																"type": "Expression"
															}
														}
													}
												],
												"outputs": [
													{
														"referenceName": "json_Aithusa",
														"type": "DatasetReference",
														"parameters": {}
													}
												]
											}
										]
									}
								},
								{
									"name": "Set stopUntil after fail",
									"type": "SetVariable",
									"dependsOn": [
										{
											"activity": "If specific date with token",
											"dependencyConditions": [
												"Failed"
											]
										},
										{
											"activity": "Extract Next Token Aithusa",
											"dependencyConditions": [
												"Failed"
											]
										},
										{
											"activity": "Fail1",
											"dependencyConditions": [
												"Succeeded"
											]
										},
										{
											"activity": "Fail2",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"variableName": "stopUntil",
										"value": "'true'"
									}
								},
								{
									"name": "Fail1",
									"type": "Fail",
									"dependsOn": [
										{
											"activity": "Extract Next Token Aithusa",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"message": "sad",
										"errorCode": "500"
									}
								},
								{
									"name": "Fail2",
									"type": "Fail",
									"dependsOn": [
										{
											"activity": "If specific date with token",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"message": "sad2",
										"errorCode": "500"
									}
								}
							],
							"timeout": "0.12:00:00"
						}
					},
					{
						"name": "Set variable1",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "If specific date",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "stopUntil",
							"value": "false"
						}
					},
					{
						"name": "Delete NATO Temp file",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "Until GET Tweets",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "json_Aithusa",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Merge JSONs and Convert to CSV",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Delete NATO Temp file",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Merge JSONs and Convert to CSV for Aithusa",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"integrationRuntime": {
								"referenceName": "WarmIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "End year",
						"type": "SetVariable",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"variableName": "end_year",
							"value": "2023"
						}
					},
					{
						"name": "End month",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "End year",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "end_month",
							"value": "03"
						}
					},
					{
						"name": "End day",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "End month",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "end_day",
							"value": "26"
						}
					},
					{
						"name": "End hour",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "End day",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "end_hour",
							"value": "00"
						}
					},
					{
						"name": "End minute",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "End hour",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "end_minute",
							"value": "30"
						}
					},
					{
						"name": "Start year",
						"type": "SetVariable",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"variableName": "start_year",
							"value": "2023"
						}
					},
					{
						"name": "Start month",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Start year",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "start_month",
							"value": "03"
						}
					},
					{
						"name": "Start day",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Start month",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "start_day",
							"value": "26"
						}
					},
					{
						"name": "Start hour",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Start day",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "start_hour",
							"value": "00"
						}
					},
					{
						"name": "Start minute",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Start hour",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "start_minute",
							"value": "00"
						}
					},
					{
						"name": "Use date range",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Start minute",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "End minute",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "specific_date",
							"value": true
						}
					},
					{
						"name": "If specific date",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "Delete Previous Merged Output files",
								"dependencyConditions": [
									"Succeeded"
								]
							},
							{
								"activity": "Delete Previous Output Files",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@variables('specific_date')",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Initial GET Past 7 Days",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "RestSource",
											"httpRequestTimeout": "00:01:40",
											"requestInterval": "00.00:00:00.010",
											"requestMethod": "GET",
											"paginationRules": {
												"supportRFC5988": "true"
											}
										},
										"sink": {
											"type": "JsonSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "JsonWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "RestResource_Aithusa_7days",
											"type": "DatasetReference",
											"parameters": {
												"query": {
													"value": "@variables('Query')",
													"type": "Expression"
												},
												"tweet_fields": {
													"value": "@variables('Tweet Fields')",
													"type": "Expression"
												},
												"max_results": {
													"value": "@variables('max_results')",
													"type": "Expression"
												}
											}
										}
									],
									"outputs": [
										{
											"referenceName": "json_Aithusa",
											"type": "DatasetReference",
											"parameters": {}
										}
									]
								}
							],
							"ifTrueActivities": [
								{
									"name": "Initial GET with specifc date",
									"type": "Copy",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"source": {
											"type": "RestSource",
											"httpRequestTimeout": "00:01:40",
											"requestInterval": "00.00:00:00.010",
											"requestMethod": "GET",
											"paginationRules": {
												"supportRFC5988": "true"
											}
										},
										"sink": {
											"type": "JsonSink",
											"storeSettings": {
												"type": "AzureBlobFSWriteSettings"
											},
											"formatSettings": {
												"type": "JsonWriteSettings"
											}
										},
										"enableStaging": false
									},
									"inputs": [
										{
											"referenceName": "RestResource_Aithusa",
											"type": "DatasetReference",
											"parameters": {
												"Query": {
													"value": "@variables('Query')",
													"type": "Expression"
												},
												"max_results": {
													"value": "@variables('max_results')",
													"type": "Expression"
												},
												"tweet_fields": {
													"value": "@variables('Tweet Fields')",
													"type": "Expression"
												},
												"start_year": {
													"value": "@variables('start_year')",
													"type": "Expression"
												},
												"start_month": {
													"value": "@variables('start_month')",
													"type": "Expression"
												},
												"start_day": {
													"value": "@variables('start_day')",
													"type": "Expression"
												},
												"start_hour": {
													"value": "@variables('start_hour')",
													"type": "Expression"
												},
												"start_minute": {
													"value": "@variables('start_minute')",
													"type": "Expression"
												},
												"start_second": "00",
												"end_year": {
													"value": "@variables('end_year')",
													"type": "Expression"
												},
												"end_month": {
													"value": "@variables('end_month')",
													"type": "Expression"
												},
												"end_day": {
													"value": "@variables('end_day')",
													"type": "Expression"
												},
												"end_hour": {
													"value": "@variables('end_hour')",
													"type": "Expression"
												},
												"end_minute": {
													"value": "@variables('end_minute')",
													"type": "Expression"
												},
												"end_second": "00"
											}
										}
									],
									"outputs": [
										{
											"referenceName": "json_Aithusa",
											"type": "DatasetReference",
											"parameters": {}
										}
									]
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"Query": {
						"type": "String"
					},
					"max_results": {
						"type": "String"
					},
					"Tweet Fields": {
						"type": "String"
					},
					"Number of Tweets to Pull": {
						"type": "String"
					},
					"next_token": {
						"type": "String"
					},
					"stopUntil": {
						"type": "String"
					},
					"specific_date": {
						"type": "Boolean"
					},
					"end_year": {
						"type": "String"
					},
					"end_month": {
						"type": "String"
					},
					"end_day": {
						"type": "String"
					},
					"end_hour": {
						"type": "String"
					},
					"end_minute": {
						"type": "String"
					},
					"start_year": {
						"type": "String"
					},
					"start_month": {
						"type": "String"
					},
					"start_day": {
						"type": "String"
					},
					"start_hour": {
						"type": "String"
					},
					"start_minute": {
						"type": "String"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Raw_Aithusa_Outputs')]",
				"[concat(variables('workspaceId'), '/datasets/Merged_Aithusa_JSON_folder')]",
				"[concat(variables('workspaceId'), '/datasets/json_Aithusa')]",
				"[concat(variables('workspaceId'), '/dataflows/Merge JSONs and Convert to CSV for Aithusa')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/WarmIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/dataflows/Get Next Token for Aithusa')]",
				"[concat(variables('workspaceId'), '/datasets/RestResource_Aithusa_7days')]",
				"[concat(variables('workspaceId'), '/datasets/RestResource_Aithusa')]",
				"[concat(variables('workspaceId'), '/datasets/RestResource_Aithusa_7days_NextToken')]",
				"[concat(variables('workspaceId'), '/datasets/RestResource_Aithusa_withToken')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LookUp_LastModified')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Get Metadata1",
						"type": "GetMetadata",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Individual_NATO_Folder",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"childItems"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@activity('Get Metadata1').output.childitems",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Get Metadata2",
									"type": "GetMetadata",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataset": {
											"referenceName": "inputFolder_file_Dyn",
											"type": "DatasetReference",
											"parameters": {
												"FileName": {
													"value": "@item().name",
													"type": "Expression"
												}
											}
										},
										"fieldList": [
											"itemName",
											"lastModified"
										],
										"storeSettings": {
											"type": "AzureBlobFSReadSettings",
											"recursive": true,
											"enablePartitionDiscovery": false
										},
										"formatSettings": {
											"type": "DelimitedTextReadSettings"
										}
									}
								},
								{
									"name": "If Condition1",
									"type": "IfCondition",
									"dependsOn": [
										{
											"activity": "Get Metadata2",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"expression": {
											"value": "@greater(formatDateTime(activity('Get Metadata2').output.lastModified,'yyyyMMddHHmmss'), formatDateTime(variables('PreviousModifiedDate'),'yyyyMMddHHmmss'))",
											"type": "Expression"
										},
										"ifTrueActivities": [
											{
												"name": "Set variable1",
												"type": "SetVariable",
												"dependsOn": [],
												"userProperties": [],
												"typeProperties": {
													"variableName": "latestFileName",
													"value": {
														"value": "@activity('Get Metadata2').output.itemName",
														"type": "Expression"
													}
												}
											}
										]
									}
								},
								{
									"name": "Set variable2",
									"type": "SetVariable",
									"dependsOn": [
										{
											"activity": "If Condition1",
											"dependencyConditions": [
												"Succeeded"
											]
										}
									],
									"userProperties": [],
									"typeProperties": {
										"variableName": "PreviousModifiedDate",
										"value": {
											"value": "@activity('Get Metadata2').output.lastModified",
											"type": "Expression"
										}
									}
								}
							]
						}
					},
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "ForEach1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".csv"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "inputFolder_file_Dyn",
								"type": "DatasetReference",
								"parameters": {
									"FileName": {
										"value": "@variables('latestFileName')",
										"type": "Expression"
									}
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Lookup_Output",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Copy data1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Find Last ID",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"integrationRuntime": {
								"referenceName": "WarmIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"traceLevel": "None",
							"cacheSinks": {
								"firstRowOnly": true
							}
						}
					},
					{
						"name": "Twitter NATO mentions",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "Data flow1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "RestSource",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": "00.00:00:00.010",
								"requestMethod": "GET",
								"paginationRules": {
									"supportRFC5988": "true"
								}
							},
							"sink": {
								"type": "JsonSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "JsonWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "RestResource_Twitter2",
								"type": "DatasetReference",
								"parameters": {
									"Query": "(\"NATO\"OR\"North Atlantic Treaty Organization\"OR%23NATO) lang:en -is:retweet -is:reply",
									"max_results": "100",
									"tweet_fields": "id,text,created_at,lang,public_metrics",
									"until_id": {
										"value": "@activity('Data flow1').output.runStatus.output.sink1.value[0].id\n",
										"type": "Expression"
									},
									"sort_order": "recency"
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Twitter_test_rt_Json",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Data flow2",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Twitter NATO mentions",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Twitter_Parse_JSON_to_CSV",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"integrationRuntime": {
								"referenceName": "WarmIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"latestFileName": {
						"type": "String"
					},
					"PreviousModifiedDate": {
						"type": "String",
						"defaultValue": "1990-01-01T05:12:22Z"
					},
					"last_id": {
						"type": "String"
					},
					"Counter": {
						"type": "String"
					},
					"next_token": {
						"type": "String"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Individual_NATO_Folder')]",
				"[concat(variables('workspaceId'), '/datasets/inputFolder_file_Dyn')]",
				"[concat(variables('workspaceId'), '/datasets/Lookup_Output')]",
				"[concat(variables('workspaceId'), '/dataflows/Find Last ID')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/WarmIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/datasets/RestResource_Twitter2')]",
				"[concat(variables('workspaceId'), '/datasets/Twitter_test_rt_Json')]",
				"[concat(variables('workspaceId'), '/dataflows/Twitter_Parse_JSON_to_CSV')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Run in Sequence')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Execute Pipeline1",
						"type": "ExecutePipeline",
						"dependsOn": [
							{
								"activity": "Delete All Look Up Files",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"pipeline": {
								"referenceName": "Twitter_GET",
								"type": "PipelineReference"
							},
							"waitOnCompletion": true,
							"parameters": {}
						}
					},
					{
						"name": "ForEach1",
						"type": "ForEach",
						"dependsOn": [
							{
								"activity": "Execute Pipeline1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"items": {
								"value": "@range(0,899)",
								"type": "Expression"
							},
							"isSequential": true,
							"activities": [
								{
									"name": "Execute Pipeline2",
									"type": "ExecutePipeline",
									"dependsOn": [],
									"userProperties": [],
									"typeProperties": {
										"pipeline": {
											"referenceName": "LookUp_LastModified",
											"type": "PipelineReference"
										},
										"waitOnCompletion": true,
										"parameters": {}
									}
								}
							]
						}
					},
					{
						"name": "Delete All Individual Files",
						"type": "Delete",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Twitter_Test_RT_DelimitedText1",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Delete All Look Up Files",
						"type": "Delete",
						"dependsOn": [
							{
								"activity": "Delete All Individual Files",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "Lookup_Output",
								"type": "DatasetReference",
								"parameters": {}
							},
							"enableLogging": false,
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							}
						}
					},
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [
							{
								"activity": "ForEach1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"wildcardFileName": "Twitter*",
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "DelimitedTextSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings",
									"copyBehavior": "MergeFiles"
								},
								"formatSettings": {
									"type": "DelimitedTextWriteSettings",
									"quoteAllText": true,
									"fileExtension": ".csv"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "Twitter_Test_RT_DelimitedText1",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "Merged_NATO",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/pipelines/Twitter_GET')]",
				"[concat(variables('workspaceId'), '/datasets/Twitter_Test_RT_DelimitedText1')]",
				"[concat(variables('workspaceId'), '/datasets/Lookup_Output')]",
				"[concat(variables('workspaceId'), '/datasets/Merged_NATO')]",
				"[concat(variables('workspaceId'), '/pipelines/LookUp_LastModified')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Twitter_GET')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Twitter NATO mentions",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "RestSource",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": "00.00:00:00.010",
								"requestMethod": "GET",
								"paginationRules": {
									"supportRFC5988": "true"
								}
							},
							"sink": {
								"type": "JsonSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "JsonWriteSettings"
								}
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "RestResource_Twitter",
								"type": "DatasetReference",
								"parameters": {
									"Query": "(\"NATO\"OR\"North Atlantic Treaty Organization\"OR%23NATO) lang:en -is:retweet -is:reply",
									"max_results": "100",
									"tweet_fields": "id,text,created_at,lang,public_metrics",
									"start_year": "2023",
									"start_month": "03",
									"start_day": "11",
									"start_hour": "20",
									"start_minute": "00",
									"start_second": "01",
									"end_year": "2023",
									"end_month": "03",
									"end_day": "17",
									"end_hour": "20",
									"end_minute": "00",
									"end_second": "01",
									"sort_order": "recency"
								}
							}
						],
						"outputs": [
							{
								"referenceName": "Twitter_test_rt_Json",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					},
					{
						"name": "Convert JSON to CSV",
						"type": "ExecuteDataFlow",
						"dependsOn": [
							{
								"activity": "Twitter NATO mentions",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Twitter_Parse_JSON_to_CSV",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"integrationRuntime": {
								"referenceName": "WarmIntegrationRuntime",
								"type": "IntegrationRuntimeReference"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"filenumber": {
						"type": "String"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/RestResource_Twitter')]",
				"[concat(variables('workspaceId'), '/datasets/Twitter_test_rt_Json')]",
				"[concat(variables('workspaceId'), '/dataflows/Twitter_Parse_JSON_to_CSV')]",
				"[concat(variables('workspaceId'), '/integrationRuntimes/WarmIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Twitter_Loop')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "AzureSqlSource",
								"queryTimeout": "02:00:00",
								"partitionOption": "None"
							},
							"sink": {
								"type": "RestSink",
								"httpRequestTimeout": "00:01:40",
								"requestInterval": 10,
								"requestMethod": "POST",
								"writeBatchSize": 10000,
								"httpCompressionType": "none"
							},
							"enableStaging": false
						},
						"inputs": [
							{
								"referenceName": "AzureSqlTable1",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "RestResource_Aithusa",
								"type": "DatasetReference",
								"parameters": {
									"Query": "NATO",
									"max_results": "10",
									"tweet_fields": "id,text,created_at,lang,public_metrics",
									"start_year": "2023",
									"start_month": "03",
									"start_day": "05",
									"start_hour": "00",
									"start_minute": "00",
									"start_second": "01",
									"end_year": "2023",
									"end_month": "03",
									"end_day": "07",
									"end_hour": "00",
									"end_minute": "00",
									"end_second": "01"
								}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/AzureSqlTable1')]",
				"[concat(variables('workspaceId'), '/datasets/RestResource_Aithusa')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureSqlTable1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureSqlDatabase1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "AzureSqlTable",
				"schema": [],
				"typeProperties": {
					"schema": "Twitter",
					"table": "NATO_tweets_test"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureSqlDatabase1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Dataset')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "pendragon-synapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "Twitter20230305023424-00001.csv",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": [
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					},
					{
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/pendragon-synapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DedicatedSqlPoolTable1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "SqlPoolTable",
				"schema": [
					{
						"name": "id",
						"type": "bigint",
						"precision": 19
					},
					{
						"name": "created_at",
						"type": "datetime2",
						"scale": 7
					},
					{
						"name": "text",
						"type": "nvarchar"
					},
					{
						"name": "lang",
						"type": "nvarchar"
					},
					{
						"name": "retweet_count",
						"type": "int",
						"precision": 10
					},
					{
						"name": "reply_count",
						"type": "int",
						"precision": 10
					},
					{
						"name": "like_count",
						"type": "int",
						"precision": 10
					},
					{
						"name": "quote_count",
						"type": "int",
						"precision": 10
					},
					{
						"name": "impression_count",
						"type": "int",
						"precision": 10
					}
				],
				"typeProperties": {
					"schema": "dbo",
					"table": "NATO_Tweets1"
				},
				"sqlPool": {
					"referenceName": "SQLPoolTest",
					"type": "SqlPoolReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/sqlPools/SQLPoolTest')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Find_minid_input')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Tweets/Individual_files/Lookup_Output",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "id",
						"type": "String"
					},
					{
						"name": "created_at",
						"type": "String"
					},
					{
						"name": "text",
						"type": "String"
					},
					{
						"name": "lang",
						"type": "String"
					},
					{
						"name": "retweet_count",
						"type": "String"
					},
					{
						"name": "reply_count",
						"type": "String"
					},
					{
						"name": "like_count",
						"type": "String"
					},
					{
						"name": "quote_count",
						"type": "String"
					},
					{
						"name": "impression_count",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Individual_NATO_Folder')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Tweets/Individual_files/NATO_Mentions",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Json1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "pendragon-synapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "RedditTest1dataset",
						"fileSystem": "pendragon"
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/pendragon-synapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Lookup_Output')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Tweets/Individual_files/Lookup_Output",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MergedJSON_to_CSV')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "NATO_merged.csv",
						"folderPath": "Raw_Twitter_JSONs/Merged_Output",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "id",
						"type": "String"
					},
					{
						"name": "created_at",
						"type": "String"
					},
					{
						"name": "text",
						"type": "String"
					},
					{
						"name": "lang",
						"type": "String"
					},
					{
						"name": "retweet_count",
						"type": "String"
					},
					{
						"name": "reply_count",
						"type": "String"
					},
					{
						"name": "like_count",
						"type": "String"
					},
					{
						"name": "quote_count",
						"type": "String"
					},
					{
						"name": "impression_count",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/MergedJSON_to_CSV_Aithusa')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "NATO_merged.csv",
						"folderPath": "Twitter_Aithusa/Merged_Output",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "id",
						"type": "String"
					},
					{
						"name": "created_at",
						"type": "String"
					},
					{
						"name": "text",
						"type": "String"
					},
					{
						"name": "lang",
						"type": "String"
					},
					{
						"name": "retweet_count",
						"type": "String"
					},
					{
						"name": "reply_count",
						"type": "String"
					},
					{
						"name": "like_count",
						"type": "String"
					},
					{
						"name": "quote_count",
						"type": "String"
					},
					{
						"name": "impression_count",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Merged_Aithusa_JSON_folder')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Twitter_Aithusa/Merged_Output",
						"fileSystem": "pendragon"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"data": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"lang": {
										"type": "string"
									},
									"text": {
										"type": "string"
									},
									"id": {
										"type": "string"
									},
									"public_metrics": {
										"type": "object",
										"properties": {
											"retweet_count": {
												"type": "integer"
											},
											"reply_count": {
												"type": "integer"
											},
											"like_count": {
												"type": "integer"
											},
											"quote_count": {
												"type": "integer"
											},
											"impression_count": {
												"type": "integer"
											}
										}
									},
									"created_at": {
										"type": "string"
									},
									"edit_history_tweet_ids": {
										"type": "array",
										"items": {
											"type": "string"
										}
									}
								}
							}
						},
						"meta": {
							"type": "object",
							"properties": {
								"newest_id": {
									"type": "string"
								},
								"oldest_id": {
									"type": "string"
								},
								"result_count": {
									"type": "integer"
								},
								"next_token": {
									"type": "string"
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Merged_JSON_folder')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Raw_Twitter_JSONs/Merged_Output",
						"fileSystem": "pendragon"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"data": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"lang": {
										"type": "string"
									},
									"text": {
										"type": "string"
									},
									"id": {
										"type": "string"
									},
									"public_metrics": {
										"type": "object",
										"properties": {
											"retweet_count": {
												"type": "integer"
											},
											"reply_count": {
												"type": "integer"
											},
											"like_count": {
												"type": "integer"
											},
											"quote_count": {
												"type": "integer"
											},
											"impression_count": {
												"type": "integer"
											}
										}
									},
									"created_at": {
										"type": "string"
									},
									"edit_history_tweet_ids": {
										"type": "array",
										"items": {
											"type": "string"
										}
									}
								}
							}
						},
						"meta": {
							"type": "object",
							"properties": {
								"newest_id": {
									"type": "string"
								},
								"oldest_id": {
									"type": "string"
								},
								"result_count": {
									"type": "integer"
								},
								"next_token": {
									"type": "string"
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Merged_Json')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@concat('Twitter','_NATO_',utcnow(),'.json')",
							"type": "Expression"
						},
						"folderPath": "Raw_Twitter_JSONs/Merged_Output",
						"fileSystem": "pendragon"
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Merged_NATO')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@concat('merged_NATO',utcNow(),'.csv')",
							"type": "Expression"
						},
						"folderPath": "Tweets/Combined_files/NATO_mentions",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "id",
						"type": "String"
					},
					{
						"name": "created_at",
						"type": "String"
					},
					{
						"name": "text",
						"type": "String"
					},
					{
						"name": "lang",
						"type": "String"
					},
					{
						"name": "retweet_count",
						"type": "String"
					},
					{
						"name": "reply_count",
						"type": "String"
					},
					{
						"name": "like_count",
						"type": "String"
					},
					{
						"name": "quote_count",
						"type": "String"
					},
					{
						"name": "impression_count",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Merged_output_csv')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Raw_Twitter_JSONs/Merged_Output",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"rowDelimiter": "\n",
					"escapeChar": "\"",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "id",
						"type": "String"
					},
					{
						"name": "created_at",
						"type": "String"
					},
					{
						"name": "text",
						"type": "String"
					},
					{
						"name": "lang",
						"type": "String"
					},
					{
						"name": "retweet_count",
						"type": "String"
					},
					{
						"name": "reply_count",
						"type": "String"
					},
					{
						"name": "like_count",
						"type": "String"
					},
					{
						"name": "quote_count",
						"type": "String"
					},
					{
						"name": "impression_count",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Raw_Aithusa_Outputs')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Twitter_Aithusa/Output",
						"fileSystem": "pendragon"
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Raw_Aithusa_Outputs_withScheme')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Twitter_Aithusa/Output",
						"fileSystem": "pendragon"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"data": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"edit_history_tweet_ids": {
										"type": "array",
										"items": {
											"type": "string"
										}
									},
									"id": {
										"type": "string"
									},
									"created_at": {
										"type": "string"
									},
									"text": {
										"type": "string"
									},
									"public_metrics": {
										"type": "object",
										"properties": {
											"retweet_count": {
												"type": "integer"
											},
											"reply_count": {
												"type": "integer"
											},
											"like_count": {
												"type": "integer"
											},
											"quote_count": {
												"type": "integer"
											},
											"impression_count": {
												"type": "integer"
											}
										}
									},
									"lang": {
										"type": "string"
									}
								}
							}
						},
						"meta": {
							"type": "object",
							"properties": {
								"newest_id": {
									"type": "string"
								},
								"oldest_id": {
									"type": "string"
								},
								"result_count": {
									"type": "integer"
								},
								"next_token": {
									"type": "string"
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Raw_Twitter_Outputs')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Raw_Twitter_JSONs/Output",
						"fileSystem": "pendragon"
					}
				},
				"schema": {}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Raw_Twitter_Outputs1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Raw_Twitter_JSONs/Output",
						"fileSystem": "pendragon"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"data": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"id": {
										"type": "string"
									},
									"lang": {
										"type": "string"
									},
									"public_metrics": {
										"type": "object",
										"properties": {
											"retweet_count": {
												"type": "integer"
											},
											"reply_count": {
												"type": "integer"
											},
											"like_count": {
												"type": "integer"
											},
											"quote_count": {
												"type": "integer"
											},
											"impression_count": {
												"type": "integer"
											}
										}
									},
									"edit_history_tweet_ids": {
										"type": "array",
										"items": {
											"type": "string"
										}
									},
									"text": {
										"type": "string"
									},
									"created_at": {
										"type": "string"
									}
								}
							}
						},
						"meta": {
							"type": "object",
							"properties": {
								"newest_id": {
									"type": "string"
								},
								"oldest_id": {
									"type": "string"
								},
								"result_count": {
									"type": "integer"
								},
								"next_token": {
									"type": "string"
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestResourceTwitter7days')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "RestService_Twitter_7days",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"query": {
						"type": "string",
						"defaultValue": "NATO"
					},
					"tweet_fields": {
						"type": "string",
						"defaultValue": "id,text,created_at,lang,public_metrics"
					},
					"max_results": {
						"type": "string",
						"defaultValue": "10"
					}
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@concat('/2/tweets/search/recent?query=',dataset().query,'&tweet.fields=',dataset().tweet_fields,'&max_results=',dataset().max_results)",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/RestService_Twitter_7days')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestResource_Aithusa')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Twitter_RestService_ Aithusa",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Query": {
						"type": "string"
					},
					"max_results": {
						"type": "string"
					},
					"tweet_fields": {
						"type": "string"
					},
					"start_year": {
						"type": "string"
					},
					"start_month": {
						"type": "string"
					},
					"start_day": {
						"type": "string"
					},
					"start_hour": {
						"type": "string"
					},
					"start_minute": {
						"type": "string"
					},
					"start_second": {
						"type": "string"
					},
					"end_year": {
						"type": "string"
					},
					"end_month": {
						"type": "string"
					},
					"end_day": {
						"type": "string"
					},
					"end_hour": {
						"type": "string"
					},
					"end_minute": {
						"type": "string"
					},
					"end_second": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@concat('/2/tweets/search/recent?query=',dataset().Query,'&start_time=',dataset().start_year,'-',dataset().start_month,'-',dataset().start_day,'T',dataset().start_hour,':',dataset().start_minute,':',dataset().start_second,'.000Z','&end_time=',dataset().end_year,'-',dataset().end_month,'-',dataset().end_day,'T',dataset().end_hour,':',dataset().end_minute,':',dataset().end_second,'.000Z','&tweet.fields=',dataset().tweet_fields,'&max_results=',dataset().max_results)",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Twitter_RestService_ Aithusa')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestResource_Aithusa_7days')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Twitter_RestService_ Aithusa",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"query": {
						"type": "string"
					},
					"tweet_fields": {
						"type": "string"
					},
					"max_results": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@concat('/2/tweets/search/recent?query=',dataset().query,'&tweet.fields=',dataset().tweet_fields,'&max_results=',dataset().max_results)",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Twitter_RestService_ Aithusa')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestResource_Aithusa_7days_NextToken')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Twitter_RestService_ Aithusa",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"query": {
						"type": "string"
					},
					"tweet_fields": {
						"type": "string"
					},
					"max_results": {
						"type": "string"
					},
					"next_token": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@concat('/2/tweets/search/recent?query=',dataset().query,'&tweet.fields=',dataset().tweet_fields,'&max_results=',dataset().max_results,'&next_token=',dataset().next_token)",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Twitter_RestService_ Aithusa')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestResource_Aithusa_withToken')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Twitter_RestService_ Aithusa",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Query": {
						"type": "string"
					},
					"max_results": {
						"type": "string"
					},
					"tweet_fields": {
						"type": "string"
					},
					"start_year": {
						"type": "string"
					},
					"start_month": {
						"type": "string"
					},
					"start_day": {
						"type": "string"
					},
					"start_hour": {
						"type": "string"
					},
					"start_minute": {
						"type": "string"
					},
					"start_second": {
						"type": "string"
					},
					"end_year": {
						"type": "string"
					},
					"end_month": {
						"type": "string"
					},
					"end_day": {
						"type": "string"
					},
					"end_hour": {
						"type": "string"
					},
					"end_minute": {
						"type": "string"
					},
					"end_second": {
						"type": "string"
					},
					"next_token": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@concat('/2/tweets/search/recent?query=',dataset().Query,'&start_time=',dataset().start_year,'-',dataset().start_month,'-',dataset().start_day,'T',dataset().start_hour,':',dataset().start_minute,':',dataset().start_second,'.000Z','&end_time=',dataset().end_year,'-',dataset().end_month,'-',dataset().end_day,'T',dataset().end_hour,':',dataset().end_minute,':',dataset().end_second,'.000Z','&tweet.fields=',dataset().tweet_fields,'&max_results=',dataset().max_results,'&next_token=',dataset().next_token)",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Twitter_RestService_ Aithusa')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestResource_Next_Token')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "RestService_Next_Token",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"query": {
						"type": "string",
						"defaultValue": "NATO"
					},
					"tweet_fields": {
						"type": "string",
						"defaultValue": "id,created_at,text,lang,public_metrics"
					},
					"max_results": {
						"type": "string",
						"defaultValue": "10"
					},
					"next_token": {
						"type": "string",
						"defaultValue": "b26v89c19zqg8o3fqka107quvh02v90tb138wylvg69od"
					}
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@concat('/2/tweets/search/recent?query=',dataset().query,'&tweet.fields=',dataset().tweet_fields,'&max_results=',dataset().max_results,'&next_token=',dataset().next_token)",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/RestService_Next_Token')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestResource_Twitter')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Twitter_RestService_AS",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Query": {
						"type": "string",
						"defaultValue": "NATO"
					},
					"max_results": {
						"type": "string",
						"defaultValue": "10"
					},
					"tweet_fields": {
						"type": "string",
						"defaultValue": "id,text,created_at,lang,public_metrics"
					},
					"start_year": {
						"type": "string",
						"defaultValue": "2023"
					},
					"start_month": {
						"type": "string",
						"defaultValue": "03"
					},
					"start_day": {
						"type": "string",
						"defaultValue": "05"
					},
					"start_hour": {
						"type": "string",
						"defaultValue": "00"
					},
					"start_minute": {
						"type": "string",
						"defaultValue": "00"
					},
					"start_second": {
						"type": "string",
						"defaultValue": "01"
					},
					"end_year": {
						"type": "string",
						"defaultValue": "2023"
					},
					"end_month": {
						"type": "string",
						"defaultValue": "03"
					},
					"end_day": {
						"type": "string",
						"defaultValue": "07"
					},
					"end_hour": {
						"type": "string",
						"defaultValue": "00"
					},
					"end_minute": {
						"type": "string",
						"defaultValue": "00"
					},
					"end_second": {
						"type": "string",
						"defaultValue": "01"
					},
					"sort_order": {
						"type": "string",
						"defaultValue": "recency"
					}
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@concat('/2/tweets/search/recent?query=',dataset().Query,'&start_time=',dataset().start_year,'-',dataset().start_month,'-',dataset().start_day,'T',dataset().start_hour,':',dataset().start_minute,':',dataset().start_second,'.000Z','&end_time=',dataset().end_year,'-',dataset().end_month,'-',dataset().end_day,'T',dataset().end_hour,':',dataset().end_minute,':',dataset().end_second,'.000Z','&tweet.fields=',dataset().tweet_fields,'&max_results=',dataset().max_results,'&sort_order=',dataset().sort_order)",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Twitter_RestService_AS')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestResource_Twitter2')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "Twitter_RestService_AS",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"Query": {
						"type": "string"
					},
					"max_results": {
						"type": "string"
					},
					"tweet_fields": {
						"type": "string"
					},
					"until_id": {
						"type": "string"
					},
					"sort_order": {
						"type": "string",
						"defaultValue": "recency"
					}
				},
				"annotations": [],
				"type": "RestResource",
				"typeProperties": {
					"relativeUrl": {
						"value": "@concat('/2/tweets/search/recent?query=',dataset().Query,'&tweet.fields=',dataset().tweet_fields,'&until_id=',dataset().until_id,'&max_results=',dataset().max_results,'&sort_order=',dataset().sort_order)",
						"type": "Expression"
					}
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/Twitter_RestService_AS')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TwitterJson1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "pendragon-synapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "Twitter_Test_DynamicURL",
						"fileSystem": "pendragon"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"results": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"label": {
										"type": "null"
									},
									"name": {
										"type": "string"
									},
									"volume": {
										"type": "integer"
									},
									"retweets": {
										"type": "integer"
									},
									"tweets": {
										"type": "integer"
									},
									"reachEstimate": {
										"type": "integer"
									},
									"impressions": {
										"type": "integer"
									}
								}
							}
						},
						"orderBy": {
							"type": "string"
						},
						"orderDirection": {
							"type": "string"
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/pendragon-synapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Twitter_DelimitedText1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "pendragon-synapse-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "Twitter_Test_RT_CSV",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/pendragon-synapse-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Twitter_RawJSON_Temp')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "NATO_Temp",
						"folderPath": "Raw_Twitter_JSONs/Temp",
						"fileSystem": "pendragon"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"data": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"edit_history_tweet_ids": {
										"type": "array",
										"items": {
											"type": "string"
										}
									},
									"id": {
										"type": "string"
									},
									"created_at": {
										"type": "string"
									},
									"text": {
										"type": "string"
									},
									"public_metrics": {
										"type": "object",
										"properties": {
											"retweet_count": {
												"type": "integer"
											},
											"reply_count": {
												"type": "integer"
											},
											"like_count": {
												"type": "integer"
											},
											"quote_count": {
												"type": "integer"
											},
											"impression_count": {
												"type": "integer"
											}
										}
									},
									"lang": {
										"type": "string"
									}
								}
							}
						},
						"meta": {
							"type": "object",
							"properties": {
								"newest_id": {
									"type": "string"
								},
								"oldest_id": {
									"type": "string"
								},
								"result_count": {
									"type": "integer"
								},
								"next_token": {
									"type": "string"
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Twitter_Test_RT_DelimitedText1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"folderPath": "Tweets/Individual_files/NATO_Mentions",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"nullValue": "NA",
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "id",
						"type": "String"
					},
					{
						"name": "created_at",
						"type": "String"
					},
					{
						"name": "text",
						"type": "String"
					},
					{
						"name": "lang",
						"type": "String"
					},
					{
						"name": "retweet_count",
						"type": "String"
					},
					{
						"name": "reply_count",
						"type": "String"
					},
					{
						"name": "like_count",
						"type": "String"
					},
					{
						"name": "quote_count",
						"type": "String"
					},
					{
						"name": "impression_count",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Twitter_test_rt_Json')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "NATOmentions",
						"folderPath": "Raw_Twitter_JSONs",
						"fileSystem": "pendragon"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"data": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"created_at": {
										"type": "string"
									},
									"edit_history_tweet_ids": {
										"type": "array",
										"items": {
											"type": "string"
										}
									},
									"id": {
										"type": "string"
									},
									"public_metrics": {
										"type": "object",
										"properties": {
											"retweet_count": {
												"type": "integer"
											},
											"reply_count": {
												"type": "integer"
											},
											"like_count": {
												"type": "integer"
											},
											"quote_count": {
												"type": "integer"
											},
											"impression_count": {
												"type": "integer"
											}
										}
									},
									"text": {
										"type": "string"
									},
									"lang": {
										"type": "string"
									}
								}
							}
						},
						"meta": {
							"type": "object",
							"properties": {
								"newest_id": {
									"type": "string"
								},
								"oldest_id": {
									"type": "string"
								},
								"result_count": {
									"type": "integer"
								},
								"next_token": {
									"type": "string"
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/inputFolder_file_Dyn')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"parameters": {
					"FileName": {
						"type": "string"
					}
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": {
							"value": "@dataset().FileName",
							"type": "Expression"
						},
						"folderPath": "Tweets/Individual_files/NATO_Mentions",
						"fileSystem": "pendragon"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/json_Aithusa')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Json",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "NATO_Temp",
						"folderPath": "Twitter_Aithusa/Temp",
						"fileSystem": "pendragon"
					}
				},
				"schema": {
					"type": "object",
					"properties": {
						"data": {
							"type": "array",
							"items": {
								"type": "object",
								"properties": {
									"public_metrics": {
										"type": "object",
										"properties": {
											"retweet_count": {
												"type": "integer"
											},
											"reply_count": {
												"type": "integer"
											},
											"like_count": {
												"type": "integer"
											},
											"quote_count": {
												"type": "integer"
											},
											"impression_count": {
												"type": "integer"
											}
										}
									},
									"edit_history_tweet_ids": {
										"type": "array",
										"items": {
											"type": "string"
										}
									},
									"lang": {
										"type": "string"
									},
									"created_at": {
										"type": "string"
									},
									"text": {
										"type": "string"
									},
									"id": {
										"type": "string"
									}
								}
							}
						},
						"meta": {
							"type": "object",
							"properties": {
								"newest_id": {
									"type": "string"
								},
								"oldest_id": {
									"type": "string"
								},
								"result_count": {
									"type": "integer"
								},
								"next_token": {
									"type": "string"
								}
							}
						}
					}
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureDataLakeStorage1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('AzureDataLakeStorage1_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('AzureDataLakeStorage1_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureMLService1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureMLService",
				"typeProperties": {
					"subscriptionId": "[parameters('AzureMLService1_properties_typeProperties_subscriptionId')]",
					"resourceGroupName": "[parameters('AzureMLService1_properties_typeProperties_resourceGroupName')]",
					"mlWorkspaceName": "pendragon-ml",
					"authentication": "MSI"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureSqlDatabase1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "linked pipelines connections",
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('AzureSqlDatabase1_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureSqlDatabase2')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureSqlDatabase",
				"typeProperties": {
					"connectionString": "[parameters('AzureSqlDatabase2_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CognitiveService1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "CognitiveService",
				"typeProperties": {
					"subscriptionId": "[parameters('CognitiveService1_properties_typeProperties_subscriptionId')]",
					"resourceGroup": "spring2023-teampendragon",
					"csName": "pendragon-language",
					"csKind": "TextAnalytics",
					"csLocation": "eastus",
					"endPoint": "https://pendragon-language.cognitiveservices.azure.com/",
					"csKey": {
						"type": "AzureKeyVaultSecret",
						"store": {
							"referenceName": "PendragonKeyVault",
							"type": "LinkedServiceReference"
						},
						"secretName": "LangaugeKey"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]",
				"[concat(variables('workspaceId'), '/linkedServices/PendragonKeyVault')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PendragonKeyVault')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureKeyVault",
				"typeProperties": {
					"baseUrl": "[parameters('PendragonKeyVault_properties_typeProperties_baseUrl')]"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PowerBIWorkspace1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "PowerBIWorkspace",
				"typeProperties": {
					"workspaceID": "89f52e0a-3aeb-4050-9251-54de8e97068e",
					"tenantID": "9e857255-df57-4c47-a0c0-0546460380cb"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PowerBIWorkspacePendragon')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "PowerBIWorkspace",
				"typeProperties": {
					"tenantID": "9e857255-df57-4c47-a0c0-0546460380cb"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestService_Next_Token')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "RestService",
				"typeProperties": {
					"url": "[parameters('RestService_Next_Token_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous",
					"authHeaders": {
						"Authorization": {
							"type": "SecureString",
							"value": "**********"
						}
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/RestService_Twitter_7days')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "RestService",
				"typeProperties": {
					"url": "[parameters('RestService_Twitter_7days_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous",
					"authHeaders": {
						"Authorization": {
							"type": "SecureString",
							"value": "**********"
						}
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Twitter_RestService_ Aithusa')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "RestService",
				"typeProperties": {
					"url": "[parameters('Twitter_RestService_ Aithusa_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous",
					"authHeaders": {
						"Authorization": {
							"type": "SecureString",
							"value": "**********"
						}
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Twitter_RestService_AS')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "RestService",
				"typeProperties": {
					"url": "[parameters('Twitter_RestService_AS_properties_typeProperties_url')]",
					"enableServerCertificateValidation": true,
					"authenticationType": "Anonymous",
					"authHeaders": {
						"Authorization": {
							"type": "SecureString",
							"value": "**********"
						}
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/pendragon-synapse-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('pendragon-synapse-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/pendragon-synapse-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('pendragon-synapse-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WarmIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 10,
							"cleanup": false
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Find Last ID')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Find_minid_input",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as string,",
						"          created_at as string,",
						"          text as string,",
						"          lang as string,",
						"          retweet_count as string,",
						"          reply_count as string,",
						"          like_count as string,",
						"          quote_count as string,",
						"          impression_count as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     purgeFiles: true) ~> source1",
						"source1 aggregate(id = min(id)) ~> aggregate1",
						"aggregate1 sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: true,",
						"     saveOrder: 1) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Find_minid_input')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Get Next Token for Aithusa')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "json_Aithusa",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "json_Aithusa",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "Raw_Aithusa_Outputs",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          data as (public_metrics as (retweet_count as integer, reply_count as integer, like_count as integer, quote_count as integer, impression_count as integer), edit_history_tweet_ids as string[], lang as string, created_at as string, text as string, id as string)[],",
						"          meta as (newest_id as string, oldest_id as string, result_count as integer, next_token as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'documentPerLine') ~> source1",
						"source(output(",
						"          data as (public_metrics as (retweet_count as integer, reply_count as integer, like_count as integer, quote_count as integer, impression_count as integer), edit_history_tweet_ids as string[], lang as string, created_at as string, text as string, id as string)[],",
						"          meta as (newest_id as string, oldest_id as string, result_count as integer, next_token as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'documentPerLine') ~> source2",
						"source1 derive(next_token = meta.next_token) ~> derivedColumn1",
						"derivedColumn1 sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: true,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          next_token",
						"     )) ~> sink1",
						"source2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     filePattern:(concat('Twitter',toString(currentTimestamp(),'yyyyMMddHHmmss'),'.json')),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 2) ~> sink2"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/json_Aithusa')]",
				"[concat(variables('workspaceId'), '/datasets/Raw_Aithusa_Outputs')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Get Next Token')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Twitter_RawJSON_Temp",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "Twitter_RawJSON_Temp",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "Raw_Twitter_Outputs",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          data as (edit_history_tweet_ids as string[], id as string, created_at as string, text as string, public_metrics as (retweet_count as integer, reply_count as integer, like_count as integer, quote_count as integer, impression_count as integer), lang as string)[],",
						"          meta as (newest_id as string, oldest_id as string, result_count as integer, next_token as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'documentPerLine') ~> source1",
						"source(output(",
						"          data as (edit_history_tweet_ids as string[], id as string, created_at as string, text as string, public_metrics as (retweet_count as integer, reply_count as integer, like_count as integer, quote_count as integer, impression_count as integer), lang as string)[],",
						"          meta as (newest_id as string, oldest_id as string, result_count as integer, next_token as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'documentPerLine') ~> source2",
						"source1 derive(next_token = meta.next_token) ~> derivedColumn1",
						"derivedColumn1 sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: true,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          next_token",
						"     )) ~> sink1",
						"source2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     filePattern:(concat('Twitter',toString(currentTimestamp(),'yyyyMMddHHmmss'),'.json')),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     saveOrder: 2) ~> sink2"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Twitter_RawJSON_Temp')]",
				"[concat(variables('workspaceId'), '/datasets/Raw_Twitter_Outputs')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Get next token variable')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "json_Aithusa",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          data as (edit_history_tweet_ids as string[], id as string, created_at as string, text as string, public_metrics as (retweet_count as integer, reply_count as integer, like_count as integer, quote_count as integer, impression_count as integer), lang as string)[],",
						"          meta as (newest_id as string, oldest_id as string, result_count as integer, next_token as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'documentPerLine') ~> source1",
						"source1 derive(next_token = meta.next_token) ~> derivedColumn1",
						"derivedColumn1 sink(validateSchema: false,",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     store: 'cache',",
						"     format: 'inline',",
						"     output: true,",
						"     saveOrder: 1,",
						"     mapColumn(",
						"          next_token",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/json_Aithusa')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Merge JSON to CSV')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Raw_Twitter_Outputs1",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "MergedJSON_to_CSV",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          data as (id as string, lang as string, public_metrics as (retweet_count as integer, reply_count as integer, like_count as integer, quote_count as integer, impression_count as integer), edit_history_tweet_ids as string[], text as string, created_at as string)[],",
						"          meta as (newest_id as string, oldest_id as string, result_count as integer, next_token as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'arrayOfDocuments') ~> source1",
						"source1 foldDown(unroll(data, data),",
						"     mapColumn(",
						"          data,",
						"          meta",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 derive(id = data.id,",
						"          created_at = data.created_at,",
						"          text = replace(replace(replace(data.text, '\\n\\n', ' '), '\\n', ' '),'\\\"',''),",
						"          lang = data.lang,",
						"          retweet_count = data.public_metrics.retweet_count,",
						"          reply_count = data.public_metrics.reply_count,",
						"          like_count = data.public_metrics.like_count,",
						"          quote_count = data.public_metrics.quote_count,",
						"          impression_count = data.public_metrics.impression_count) ~> derivedColumn1",
						"derivedColumn1 sort(desc(id, false)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          created_at as string,",
						"          text as string,",
						"          lang as string,",
						"          retweet_count as string,",
						"          reply_count as string,",
						"          like_count as string,",
						"          quote_count as string,",
						"          impression_count as string",
						"     ),",
						"     partitionFileNames:[(concat('Twitter',toString(currentTimestamp(),'yyyyMMddHHmmss'),'.csv'))],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          created_at,",
						"          text,",
						"          lang,",
						"          retweet_count,",
						"          reply_count,",
						"          like_count,",
						"          quote_count,",
						"          impression_count",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Raw_Twitter_Outputs1')]",
				"[concat(variables('workspaceId'), '/datasets/MergedJSON_to_CSV')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Merge JSONs and Convert to CSV for Aithusa')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Raw_Aithusa_Outputs_withScheme",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "MergedJSON_to_CSV_Aithusa",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          data as (edit_history_tweet_ids as string[], id as string, created_at as string, text as string, public_metrics as (retweet_count as integer, reply_count as integer, like_count as integer, quote_count as integer, impression_count as integer), lang as string)[],",
						"          meta as (newest_id as string, oldest_id as string, result_count as integer, next_token as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'arrayOfDocuments') ~> source1",
						"source1 foldDown(unroll(data, data),",
						"     mapColumn(",
						"          data,",
						"          meta",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 derive(id = data.id,",
						"          created_at = data.created_at,",
						"          text = replace(replace(replace(data.text, '\\n\\n', ' '), '\\n', ' '),'\\\"',''),",
						"          lang = data.lang,",
						"          retweet_count = data.public_metrics.retweet_count,",
						"          reply_count = data.public_metrics.reply_count,",
						"          like_count = data.public_metrics.like_count,",
						"          quote_count = data.public_metrics.quote_count,",
						"          impression_count = data.public_metrics.impression_count) ~> derivedColumn1",
						"derivedColumn1 sort(desc(id, false)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          created_at as string,",
						"          text as string,",
						"          lang as string,",
						"          retweet_count as string,",
						"          reply_count as string,",
						"          like_count as string,",
						"          quote_count as string,",
						"          impression_count as string",
						"     ),",
						"     partitionFileNames:[(concat('Twitter',toString(currentTimestamp(),'yyyyMMddHHmmss'),'.csv'))],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          created_at,",
						"          text,",
						"          lang,",
						"          retweet_count,",
						"          reply_count,",
						"          like_count,",
						"          quote_count,",
						"          impression_count",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Raw_Aithusa_Outputs_withScheme')]",
				"[concat(variables('workspaceId'), '/datasets/MergedJSON_to_CSV_Aithusa')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Twitter_Parse_JSON_to_CSV')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "Twitter_test_rt_Json",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Twitter_Test_RT_DelimitedText1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "flatten1"
						},
						{
							"name": "derivedColumn1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          data as (created_at as string, edit_history_tweet_ids as string[], id as string, public_metrics as (retweet_count as integer, reply_count as integer, like_count as integer, quote_count as integer, impression_count as integer), text as string, lang as string)[],",
						"          meta as (newest_id as string, oldest_id as string, result_count as integer, next_token as string)",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     documentForm: 'documentPerLine') ~> source1",
						"source1 foldDown(unroll(data, data),",
						"     mapColumn(",
						"          data,",
						"          meta",
						"     ),",
						"     skipDuplicateMapInputs: false,",
						"     skipDuplicateMapOutputs: false) ~> flatten1",
						"flatten1 derive(id = data.id,",
						"          created_at = data.created_at,",
						"          text = replace(replace(replace(data.text, '\\n\\n', ' '), '\\n', ' '),'\\\"',''),",
						"          lang = data.lang,",
						"          retweet_count = data.public_metrics.retweet_count,",
						"          reply_count = data.public_metrics.reply_count,",
						"          like_count = data.public_metrics.like_count,",
						"          quote_count = data.public_metrics.quote_count,",
						"          impression_count = data.public_metrics.impression_count) ~> derivedColumn1",
						"derivedColumn1 sort(asc(id, true),",
						"     partitionLevel: true) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          id as string,",
						"          created_at as string,",
						"          text as string,",
						"          lang as string,",
						"          retweet_count as string,",
						"          reply_count as string,",
						"          like_count as string,",
						"          quote_count as string,",
						"          impression_count as string",
						"     ),",
						"     filePattern:(concat('Twitter',toString(currentTimestamp(),'yyyyMMddHHmmss'),'.csv')),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          id,",
						"          created_at,",
						"          text,",
						"          lang,",
						"          retweet_count,",
						"          reply_count,",
						"          like_count,",
						"          quote_count,",
						"          impression_count",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/Twitter_test_rt_Json')]",
				"[concat(variables('workspaceId'), '/datasets/Twitter_Test_RT_DelimitedText1')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/PendragonManagedIdentityCredential')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {
					"resourceId": "/subscriptions/57cd2ff8-9306-41d0-9cad-c2052a0a8381/resourceGroups/Spring2023-TeamPendragon/providers/Microsoft.ManagedIdentity/userAssignedIdentities/PendragonManagedIdentity"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Create_NATO_Tweets1_Table')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n\nCREATE TABLE [dbo].[NATO_Tweets1]\n( \n\t[id] bigint  NOT NULL,\n\t[created_at] DATETIME2(7)  NULL,\n\t[text] NVARCHAR(4000)  NULL,\n\t[lang] nvarchar(10)  NULL,\n\t[retweet_count] INT  NULL,\n\t[reply_count] INT  NULL,\n\t[like_count] INT  NULL,\n\t[quote_count] INT  NULL,\n\t[impression_count] INT  NULL\n)\nWITH\n(\n\tDISTRIBUTION = HASH ( [id] ),\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQLPoolTest",
						"poolName": "SQLPoolTest"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Create_Timeline')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT DATEADD(second, (DATEPART(second, created_at) / 10) * 10, DATEADD(minute, DATEDIFF(minute, 0, created_at), 0)) AS IntervalStart,\n       COUNT(*) AS Count\nFROM [dbo].[NATO_Tweets1]\nGROUP BY DATEADD(second, (DATEPART(second, created_at) / 10) * 10, DATEADD(minute, DATEDIFF(minute, 0, created_at), 0))\nORDER BY IntervalStart;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQLPoolTest",
						"poolName": "SQLPoolTest"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DeleteAllProcedure')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE PROCEDURE DeleteAllRowsFromNatoTweets1\nAS\nBEGIN\n    DELETE FROM [dbo].[NATO_Tweets1];\nEND;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQLPoolTest",
						"poolName": "SQLPoolTest"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DeleteAllRows')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "DELETE FROM [dbo].[NATO_Tweets1];\nGO\n\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ServerlessSQLPoolTest",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT COUNT(*) FROM [dbo].[NATO_Tweets1];\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQLPoolTest",
						"poolName": "SQLPoolTest"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 2')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE PROCEDURE tweetsClean\nAS\nBEGIN\n     FROM [dbo].[NATO_Tweets1];\nEND;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 3')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "DROP TABLE [dbo].[NATO_Tweets1]\nGO\n\nSET ANSI_NULLS ON\nGO\nSET QUOTED_IDENTIFIER ON\nGO\n\nCREATE TABLE [dbo].[NATO_Tweets1]\n( \n\t[id] [bigint]  NOT NULL,\n\t[created_at] [datetime2](7)  NULL,\n\t[text] [nvarchar](4000)  NULL,\n\t[lang] [nvarchar](10)  NULL,\n\t[retweet_count] [int]  NULL,\n\t[reply_count] [int]  NULL,\n\t[like_count] [int]  NULL,\n\t[quote_count] [int]  NULL,\n\t[impression_count] [int]  NULL,\n\t[cleanText] [nvarchar](4000)\n)\nWITH\n(\n\tDISTRIBUTION = HASH ( [id] ),\n\tCLUSTERED COLUMNSTORE INDEX\n)\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQLPoolTest",
						"poolName": "SQLPoolTest"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 4')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE PROC [dbo].[cleanTweets]\n\nAS\nBEGIN\nupdate dbo.NATO_Tweets1 set cleanText=text;\nUPDATE dbo.NATO_Tweets1 \nSET text = CASE \n\n             WHEN CHARINDEX('https', text) > 0 \n             THEN LEFT(text, CHARINDEX('https', text) - 1) \n             ELSE text \n           END;\n           delete from dbo.NATO_Tweets1 where text='';\nEND\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "SQLPoolTest",
						"poolName": "SQLPoolTest"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Cleaning_test')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPoolTest",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "f30465a1-c4f3-4732-a0ad-e496e7e57764"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/57cd2ff8-9306-41d0-9cad-c2052a0a8381/resourceGroups/Spring2023-TeamPendragon/providers/Microsoft.Synapse/workspaces/pendragon-synapse/bigDataPools/SparkPoolTest",
						"name": "SparkPoolTest",
						"type": "Spark",
						"endpoint": "https://pendragon-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPoolTest",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"# Install bertopic\n",
							"!pip install bertopic"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from bertopic import BERTopic\n",
							""
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Data processing\n",
							"import pandas as pd\n",
							"import numpy as np\n",
							"# Text preprocessiong\n",
							"import nltk\n",
							"nltk.download('stopwords')\n",
							"nltk.download('omw-1.4')\n",
							"nltk.download('wordnet')\n",
							"wn = nltk.WordNetLemmatizer()\n",
							"# Topic model\n",
							"from bertopic import BERTopic\n",
							"# Dimension reduction\n",
							"from umap import UMAP"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"!pip install transformers[torch]\n",
							"from transformers import pipeline;\n",
							""
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
							"data = [\"I love you\", \"I hate you\"]\n",
							"\n",
							"sentiment_pipeline(data)"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#%%pyspark \n",
							"\n",
							"df = spark.read.load('abfss://pendragon@pendragon.dfs.core.windows.net/Raw_Twitter_JSONs/Merged_Output/Twitter20230325213227.csv', format='csv') ## If header exists uncomment line below ##, header=True ) \n",
							"\n",
							"display(df.limit(10))"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mssparkutils.fs.mount( \n",
							"    \"abfss://pendragon@pendragon.dfs.core.windows.net\", \n",
							"    \"/test\", \n",
							"    {\"linkedService\":\"mygen2account\"} "
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Add required imports\n",
							"import com.microsoft.spark.sqlanalytics\n",
							"from com.microsoft.spark.sqlanalytics.Constants import Constants\n",
							"from pyspark.sql.functions import col\n",
							"\n",
							"# Name of the SQL Dedicated Pool or database where to run the query\n",
							"# Database can be specified as a Spark Config or as a Constant - Constants.DATABASE\n",
							"spark.conf.set(\"spark.sqlanalyticsconnector.dw.database\", \"SQLPoolTest\")\n",
							"\n",
							"# Read from a query\n",
							"# Query can be provided either as an argument to synapsesql or as a Constant - Constants.QUERY\n",
							"df = (spark.read\n",
							"                     # Name of the SQL Dedicated Pool or database where to run the query\n",
							"                     # Database can be specified as a Spark Config - spark.sqlanalyticsconnector.dw.database or as a Constant - Constants.DATABASE\n",
							"                     .option(Constants.DATABASE, \"SQLPoolTest\")\n",
							"                     # If `Constants.SERVER` is not provided, the `<database_name>` from the three-part table name argument\n",
							"                     # to `synapsesql` method is used to infer the Synapse Dedicated SQL End Point.\n",
							"                     .option(Constants.SERVER, \"pendragon-synapse.sql.azuresynapse.net\")\n",
							"                     # Defaults to storage path defined in the runtime configurations\n",
							"                     .option(Constants.TEMP_FOLDER, \"abfss://pendragon@pendragon.dfs.core.windows.net/NotebookStaging\")\n",
							"                     # query from which data will be read\n",
							"                     .option(Constants.QUERY, \"select * from dbo.NATO_Tweets1\")\n",
							"                     .synapsesql())"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df.show()"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#regex cleaning\n",
							"\n",
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": [],
						"execution_count": null
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CleansDataFromFolder')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPoolTest",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "9a20c3d9-e847-4523-9b56-873570d32737"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/57cd2ff8-9306-41d0-9cad-c2052a0a8381/resourceGroups/Spring2023-TeamPendragon/providers/Microsoft.Synapse/workspaces/pendragon-synapse/bigDataPools/SparkPoolTest",
						"name": "SparkPoolTest",
						"type": "Spark",
						"endpoint": "https://pendragon-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPoolTest",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"!pip install azure-storage-file-datalake"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# azureml-core of version 1.0.72 or higher is required\r\n",
							"# azureml-dataprep[pandas] of version 1.1.34 or higher is required\r\n",
							"from azureml.core import Workspace, Dataset\r\n",
							"\r\n",
							"subscription_id = '57cd2ff8-9306-41d0-9cad-c2052a0a8381'\r\n",
							"resource_group = 'Spring2023-TeamPendragon'\r\n",
							"workspace_name = 'pendragon-ml'\r\n",
							"\r\n",
							"workspace = Workspace(subscription_id, resource_group, workspace_name)\r\n",
							"\r\n",
							"dataset = Dataset.get_by_name(workspace, name='NATO_Tweets')\r\n",
							"df = dataset.to_pandas_dataframe()\r\n",
							"df\r\n",
							""
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Remove @, #, links, and emoticons"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# remove @s\r\n",
							"df['text'] = df['text'].str.replace(r'@\\w+\\s*', '')\r\n",
							"\r\n",
							"# remove hashtags\r\n",
							"df['text'] = df['text'].str.replace(r'#\\w+\\s*', '')\r\n",
							"\r\n",
							"# Remove links\r\n",
							"import re\r\n",
							"df['text'] = df['text'].apply(lambda x: re.sub(r'http\\S+', '', x))\r\n",
							"\r\n",
							"# drop rows where the 'text' column is an empty string\r\n",
							"df = df.drop(df[df['text'] == ''].index)\r\n",
							"\r\n",
							"# drop rows where the 'lang' column is not 'en'\r\n",
							"df = df.drop(df[df['lang'] != 'en'].index)\r\n",
							"\r\n",
							"# print the resulting dataframe\r\n",
							"#df.head(10)"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import re\r\n",
							"\r\n",
							"# define a regex pattern to match emoticons\r\n",
							"emoticon_pattern = re.compile(\"[\"\r\n",
							"                              u\"\\U0001F600-\\U0001F64F\"  # emoticons\r\n",
							"                              u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\r\n",
							"                              u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\r\n",
							"                              u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\r\n",
							"                              \"]+\", flags=re.UNICODE)\r\n",
							"\r\n",
							"# apply the regex pattern to the 'text' column to remove emoticons\r\n",
							"df['text'] = df['text'].str.replace(emoticon_pattern, '')\r\n",
							"\r\n",
							"# print the modified DataFrame\r\n",
							"print(df['text'])"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Add a period to the end of text if one doesn't exist"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# check if each string in 'text' column ends with a period\r\n",
							"no_period_mask = ~df['text'].str.endswith('.')\r\n",
							"\r\n",
							"# add period to the end of the strings that don't end with a period\r\n",
							"df.loc[no_period_mask, 'text'] += '.'\r\n",
							"\r\n",
							"# print the modified DataFrame\r\n",
							"#print(df['text'])"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# sort the DataFrame by the 'created_at' column\r\n",
							"df = df.sort_values(by='created_at')\r\n",
							"#df.head(10)"
						],
						"outputs": [],
						"execution_count": 23
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CognitiveServices')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPoolTest",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "76d960c4-a09f-41bb-8af4-6471490a8156"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/57cd2ff8-9306-41d0-9cad-c2052a0a8381/resourceGroups/Spring2023-TeamPendragon/providers/Microsoft.Synapse/workspaces/pendragon-synapse/bigDataPools/SparkPoolTest",
						"name": "SparkPoolTest",
						"type": "Spark",
						"endpoint": "https://pendragon-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPoolTest",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"# Add required imports\r\n",
							"import com.microsoft.spark.sqlanalytics\r\n",
							"from com.microsoft.spark.sqlanalytics.Constants import Constants\r\n",
							"from pyspark.sql.functions import col\r\n",
							"\r\n",
							"# Name of the SQL Dedicated Pool or database where to run the query\r\n",
							"# Database can be specified as a Spark Config or as a Constant - Constants.DATABASE\r\n",
							"spark.conf.set(\"spark.sqlanalyticsconnector.dw.database\", \"SQLPoolTest\")\r\n",
							"\r\n",
							"# Read from a query\r\n",
							"# Query can be provided either as an argument to synapsesql or as a Constant - Constants.QUERY\r\n",
							"df = (spark.read\r\n",
							"                     # Name of the SQL Dedicated Pool or database where to run the query\r\n",
							"                     # Database can be specified as a Spark Config - spark.sqlanalyticsconnector.dw.database or as a Constant - Constants.DATABASE\r\n",
							"                     .option(Constants.DATABASE, \"SQLPoolTest\")\r\n",
							"                     # If `Constants.SERVER` is not provided, the `<database_name>` from the three-part table name argument\r\n",
							"                     # to `synapsesql` method is used to infer the Synapse Dedicated SQL End Point.\r\n",
							"                     .option(Constants.SERVER, \"pendragon-synapse.sql.azuresynapse.net\")\r\n",
							"                     # Defaults to storage path defined in the runtime configurations\r\n",
							"                     .option(Constants.TEMP_FOLDER, \"abfss://pendragon@pendragon.dfs.core.windows.net/NotebookStaging\")\r\n",
							"                     # query from which data will be read\r\n",
							"                     .option(Constants.QUERY, \"select * from dbo.NATO_Tweets1\")\r\n",
							"                     .synapsesql()\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Sentiment Analysis, Entity Extraction, Key Phrase Extraction, Named Entity Recognition"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Select sample size for testing\r\n",
							"\r\n",
							"# Sort ascending by 'created_at'\r\n",
							"from pyspark.sql.functions import desc\r\n",
							"\r\n",
							"sorted_df = df.orderBy(desc(\"created_at\"))\r\n",
							"\r\n",
							"\r\n",
							"# select the first 20 records\r\n",
							"first_20 = sorted_df.limit(20)\r\n",
							"first_20.show()"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import regexp_replace\r\n",
							"\r\n",
							"# Define the regular expression pattern to match words starting with @, &, or https\r\n",
							"regex = r'@\\w+|&\\w+|https?://\\S+|#\\w+'\r\n",
							"regex = r'\\b[@#&]\\w+|\\bhttps\\w*'\r\n",
							"\r\n",
							"# Apply the regexp_replace function to the text column and create a new column with the filtered text\r\n",
							"df_filtered = first_20.withColumn(\"text\", regexp_replace(col(\"text\"), regex, ''))\r\n",
							"\r\n",
							"# Show the filtered DataFrame\r\n",
							"df_filtered.select(\"text\").show()\r\n",
							"\r\n",
							"first_20 = df_filtered"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import synapse.ml\r\n",
							"from synapse.ml.cognitive import *\r\n",
							"from pyspark.sql.functions import col"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"print(dir(synapse.ml.cognitive))"
						],
						"outputs": [],
						"execution_count": 87
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"linked_service_name = \"CognitiveService1\""
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Sentiment"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": true
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"sent = (TextSentiment()\r\n",
							"    .setLinkedService(linked_service_name)\r\n",
							"    .setOutputCol(\"sentiment\")\r\n",
							"    .setErrorCol(\"error\"))\r\n",
							"    \r\n",
							"sent_output = sent.transform(first_20)"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sent_output.select(\"sentiment\").show()"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Convert the output to a JSON format and extract the sentiment of each text record into an array"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import json\r\n",
							"\r\n",
							"# Extract the 'sentiment' column and convert it to JSON\r\n",
							"json_output = sent_output.select(\"sentiment\").toJSON().collect()\r\n",
							"\r\n",
							"# Deserialize the JSON and extract the 'sentiment' field\r\n",
							"sentiments = [json.loads(x)[\"sentiment\"] for x in json_output]\r\n",
							"\r\n",
							"output = []\r\n",
							"\r\n",
							"# Print the 'sentiment' field for each row\r\n",
							"for sentiment in sentiments:\r\n",
							"    #print(sentiment)\r\n",
							"    output.append(sentiment['document']['sentiment'])\r\n",
							"\r\n",
							"print(output)"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Calculate the overall sentiment and the confidence scores"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import collections\r\n",
							"\r\n",
							"# Count the occurrences of each value in the array\r\n",
							"counts = collections.Counter(output)\r\n",
							"\r\n",
							"# Get the most common value and its count\r\n",
							"most_common = counts.most_common(1)[0]\r\n",
							"most_common_value = most_common[0]\r\n",
							"most_common_count = most_common[1]\r\n",
							"\r\n",
							"print(\"Most common value:\", most_common_value)\r\n",
							"print(\"Count:\", most_common_count)\r\n",
							"\r\n",
							"confidence_scores = {}\r\n",
							"\r\n",
							"total_values = len(output)\r\n",
							"\r\n",
							"for value, count in counts.items():\r\n",
							"    confidence_scores[value] = count / total_values\r\n",
							"\r\n",
							"print(\"Confidence scores:\", confidence_scores)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Entity Extraction"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# import required libraries\r\n",
							"import json\r\n",
							"from pyspark.sql.types import StructType, StructField, StringType\r\n",
							"import pyspark.sql.functions as F\r\n",
							"\r\n",
							"# First, count the total number of rows in the DataFrame\r\n",
							"num_rows = first_20.count()\r\n",
							"\r\n",
							"# Next, calculate the number of batches needed to split the DataFrame into batches of 5\r\n",
							"num_batches = int(num_rows / 5) + (num_rows % 5 > 0)\r\n",
							"\r\n",
							"# Then, use randomSplit to split the DataFrame into smaller DataFrames of equal size\r\n",
							"df_batches = first_20.randomSplit([1.0]*num_batches, seed=42)\r\n",
							"\r\n",
							"# define the schema for the output DataFrame\r\n",
							"schema = StructType([\r\n",
							"    StructField(\"entity_name\", StringType(), True),\r\n",
							"    StructField(\"entity_url\", StringType(), True)\r\n",
							"    ])\r\n",
							"\r\n",
							"# create an empty DataFrame with the defined schema\r\n",
							"output_df = spark.createDataFrame([], schema)\r\n",
							"\r\n",
							"# Finally, use limit to limit the number of rows in each DataFrame to 5\r\n",
							"for i in range(num_batches):\r\n",
							"    batch = df_batches[i].limit(5)\r\n",
							"    entity = (EntityDetector()\r\n",
							"    .setLinkedService(linked_service_name)\r\n",
							"    .setLanguage(\"en\")\r\n",
							"    .setOutputCol(\"replies\")\r\n",
							"    .setErrorCol(\"error\"))\r\n",
							"\r\n",
							"    ent_batch_output = entity.transform(batch)\r\n",
							"    #display(ent_batch_output)\r\n",
							"\r\n",
							"    # Extract the 'replies' column and convert it to JSON\r\n",
							"    json_output = ent_batch_output.select(\"replies\").toJSON().collect()\r\n",
							"\r\n",
							"    # Deserialize the JSON and extract the 'replies' field\r\n",
							"    ents = [json.loads(x)[\"replies\"] for x in json_output]\r\n",
							"\r\n",
							"    # Print the 'replies' field for each row\r\n",
							"    for each in ents:\r\n",
							"        #print(each)\r\n",
							"        # create a PySpark DataFrame from the JSON string\r\n",
							"        json_string = each\r\n",
							"        df = spark.read.json(sc.parallelize([json_string]))\r\n",
							"\r\n",
							"        # extract the 'entities' array from the 'document' column\r\n",
							"        df = df.selectExpr('explode(document.entities) as entities')\r\n",
							"\r\n",
							"        # select the 'text' and 'category' fields from the exploded 'entities' array\r\n",
							"        df = df.select('entities.name', 'entities.url')\r\n",
							"\r\n",
							"        # rename the columns\r\n",
							"        df = df.withColumnRenamed('text', 'entity_name')\r\n",
							"        df = df.withColumnRenamed('category', 'entity_url')\r\n",
							"\r\n",
							"        # show the resulting DataFrame\r\n",
							"        #df.show()\r\n",
							"\r\n",
							"        # Append the batch results dataframe to the main output dataframe\r\n",
							"        output_df = output_df.union(df)\r\n",
							"display(output_df)"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Key Phrase Extractor"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"keyPhrase = (KeyPhraseExtractor()\r\n",
							"    .setLinkedService(linked_service_name)\r\n",
							"    .setLanguageCol(\"lang\")\r\n",
							"    .setOutputCol(\"replies\")\r\n",
							"    .setErrorCol(\"error\"))\r\n",
							"\r\n",
							"keyphrase_output = keyPhrase.transform(first_20)\r\n",
							"display(keyPhrase.transform(first_20))"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Convert output to a JSON and collect the results into one array"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import json\r\n",
							"\r\n",
							"# Extract the 'sentiment' column and convert it to JSON\r\n",
							"json_output = keyphrase_output.select(\"replies\").toJSON().collect()\r\n",
							"\r\n",
							"# Deserialize the JSON and extract the 'sentiment' field\r\n",
							"keyphrases = [json.loads(x)[\"replies\"] for x in json_output]\r\n",
							"\r\n",
							"kp_output = []\r\n",
							"\r\n",
							"# Print the 'sentiment' field for each row\r\n",
							"for each in keyphrases:\r\n",
							"    #print(each)\r\n",
							"    for keyphrase in each['document']['keyPhrases']:\r\n",
							"        kp_output.append(keyphrase)\r\n",
							"\r\n",
							"print(kp_output)"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Create a dataframe for the key phrases and their count"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# Create a PySpark DataFrame from the array\r\n",
							"kp_df = spark.createDataFrame([(i, 1) for i in kp_output], ['text', 'count'])\r\n",
							"\r\n",
							"# Group by 'text' column and sum the 'count' column to get the count of each unique text\r\n",
							"kp_df = kp_df.groupBy('text').agg({'count': 'sum'})\r\n",
							"\r\n",
							"# Sort the DataFrame by the 'count' column in descending order\r\n",
							"kp_df = kp_df.sort(col('sum(count)').desc())\r\n",
							"\r\n",
							"# Show the resulting DataFrame\r\n",
							"display(kp_df)"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Named Entity Recognition"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"collapsed": false
						},
						"source": [
							"# import required libraries\r\n",
							"import json\r\n",
							"from pyspark.sql.types import StructType, StructField, StringType\r\n",
							"import pyspark.sql.functions as F\r\n",
							"\r\n",
							"# First, count the total number of rows in the DataFrame\r\n",
							"num_rows = first_20.count()\r\n",
							"\r\n",
							"# Next, calculate the number of batches needed to split the DataFrame into batches of 5\r\n",
							"num_batches = int(num_rows / 5) + (num_rows % 5 > 0)\r\n",
							"\r\n",
							"# Then, use randomSplit to split the DataFrame into smaller DataFrames of equal size\r\n",
							"df_batches = first_20.randomSplit([1.0]*num_batches, seed=42)\r\n",
							"\r\n",
							"# define the schema for the output DataFrame\r\n",
							"schema = StructType([\r\n",
							"    StructField(\"entity_text\", StringType(), True),\r\n",
							"    StructField(\"entity_category\", StringType(), True)\r\n",
							"    ])\r\n",
							"\r\n",
							"# create an empty DataFrame with the defined schema\r\n",
							"output_df = spark.createDataFrame([], schema)\r\n",
							"\r\n",
							"# Finally, use limit to limit the number of rows in each DataFrame to 5\r\n",
							"for i in range(num_batches):\r\n",
							"    batch = df_batches[i].limit(5)\r\n",
							"    ner = (NER()\r\n",
							"    .setLinkedService(linked_service_name)\r\n",
							"    .setLanguageCol(\"lang\")\r\n",
							"    .setOutputCol(\"replies\")\r\n",
							"    .setErrorCol(\"error\"))\r\n",
							"\r\n",
							"    ner_batch_output = ner.transform(batch)\r\n",
							"    #display(ner_batch_output)\r\n",
							"\r\n",
							"    # Extract the 'replies' column and convert it to JSON\r\n",
							"    json_output = ner_batch_output.select(\"replies\").toJSON().collect()\r\n",
							"\r\n",
							"    # Deserialize the JSON and extract the 'replies' field\r\n",
							"    nes = [json.loads(x)[\"replies\"] for x in json_output]\r\n",
							"\r\n",
							"    # Print the 'replies' field for each row\r\n",
							"    for each in nes:\r\n",
							"        #print(each)\r\n",
							"\r\n",
							"        # create a PySpark DataFrame from the JSON string\r\n",
							"        json_string = each\r\n",
							"        df = spark.read.json(sc.parallelize([json_string]))\r\n",
							"\r\n",
							"        # extract the 'entities' array from the 'document' column\r\n",
							"        df = df.selectExpr('explode(document.entities) as entities')\r\n",
							"\r\n",
							"        # select the 'text' and 'category' fields from the exploded 'entities' array\r\n",
							"        df = df.select('entities.text', 'entities.category')\r\n",
							"\r\n",
							"        # rename the columns\r\n",
							"        df = df.withColumnRenamed('text', 'entity_text')\r\n",
							"        df = df.withColumnRenamed('category', 'entity_category')\r\n",
							"\r\n",
							"        # show the resulting DataFrame\r\n",
							"        #df.show()\r\n",
							"\r\n",
							"        # Append the batch results dataframe to the main output dataframe\r\n",
							"        output_df = output_df.union(df)\r\n",
							"display(output_df)"
						],
						"outputs": [],
						"execution_count": 20
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/LoadfromSQLPool')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPoolTest",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "2aa6efde-df82-4393-ae30-814b3a7a34c5"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/57cd2ff8-9306-41d0-9cad-c2052a0a8381/resourceGroups/Spring2023-TeamPendragon/providers/Microsoft.Synapse/workspaces/pendragon-synapse/bigDataPools/SparkPoolTest",
						"name": "SparkPoolTest",
						"type": "Spark",
						"endpoint": "https://pendragon-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPoolTest",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Read from a query using Azure AD based authentication\r\n",
							"\r\n",
							"https://learn.microsoft.com/en-us/azure/synapse-analytics/spark/synapse-spark-sql-pool-import-export?tabs=python%2Cpython1%2Cscala2%2Cscala3%2Cscala4%2Cscala5"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Add required imports\r\n",
							"import com.microsoft.spark.sqlanalytics\r\n",
							"from com.microsoft.spark.sqlanalytics.Constants import Constants\r\n",
							"from pyspark.sql.functions import col\r\n",
							"\r\n",
							"# Name of the SQL Dedicated Pool or database where to run the query\r\n",
							"# Database can be specified as a Spark Config or as a Constant - Constants.DATABASE\r\n",
							"spark.conf.set(\"spark.sqlanalyticsconnector.dw.database\", \"SQLPoolTest\")\r\n",
							"\r\n",
							"# Read from a query\r\n",
							"# Query can be provided either as an argument to synapsesql or as a Constant - Constants.QUERY\r\n",
							"dfToReadFromQueryAsOption = (spark.read\r\n",
							"                     # Name of the SQL Dedicated Pool or database where to run the query\r\n",
							"                     # Database can be specified as a Spark Config - spark.sqlanalyticsconnector.dw.database or as a Constant - Constants.DATABASE\r\n",
							"                     .option(Constants.DATABASE, \"SQLPoolTest\")\r\n",
							"                     # If `Constants.SERVER` is not provided, the `<database_name>` from the three-part table name argument\r\n",
							"                     # to `synapsesql` method is used to infer the Synapse Dedicated SQL End Point.\r\n",
							"                     .option(Constants.SERVER, \"pendragon-synapse.sql.azuresynapse.net\")\r\n",
							"                     # Defaults to storage path defined in the runtime configurations\r\n",
							"                     .option(Constants.TEMP_FOLDER, \"abfss://pendragon@pendragon.dfs.core.windows.net/NotebookStaging\")\r\n",
							"                     # query from which data will be read\r\n",
							"                     .option(Constants.QUERY, \"select * from dbo.NATO_Tweets1\")\r\n",
							"                     .synapsesql()\r\n",
							")\r\n",
							"\r\n",
							"dfToReadFromQueryAsArgument = (spark.read\r\n",
							"                     # Name of the SQL Dedicated Pool or database where to run the query\r\n",
							"                     # Database can be specified as a Spark Config - spark.sqlanalyticsconnector.dw.database or as a Constant - Constants.DATABASE\r\n",
							"                     .option(Constants.DATABASE, \"SQLPoolTest\")\r\n",
							"                     # If `Constants.SERVER` is not provided, the `<database_name>` from the three-part table name argument\r\n",
							"                     # to `synapsesql` method is used to infer the Synapse Dedicated SQL End Point.\r\n",
							"                     .option(Constants.SERVER, \"pendragon-synapse.sql.azuresynapse.net\")\r\n",
							"                     # Defaults to storage path defined in the runtime configurations\r\n",
							"                     .option(Constants.TEMP_FOLDER, \"abfss://pendragon@pendragon.dfs.core.windows.net/NotebookStaging\")\r\n",
							"                     # query from which data will be read\r\n",
							"                     .synapsesql(\"select * from dbo.NATO_Tweets1\")\r\n",
							")\r\n",
							"\r\n",
							"# Show contents of the dataframe\r\n",
							"dfToReadFromQueryAsOption.show()\r\n",
							"dfToReadFromQueryAsArgument.show()"
						],
						"outputs": [],
						"execution_count": 40
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df = dfToReadFromQueryAsArgument"
						],
						"outputs": [],
						"execution_count": 43
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Text Analytics\r\n",
							"https://learn.microsoft.com/en-us/azure/synapse-analytics/machine-learning/tutorial-text-analytics-use-mmlspark"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import synapse.ml\r\n",
							"from synapse.ml.cognitive import *\r\n",
							"from pyspark.sql.functions import col"
						],
						"outputs": [],
						"execution_count": 48
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"linked_service_name = \"CognitiveService1\""
						],
						"outputs": [],
						"execution_count": 57
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Create a dataframe that's tied to it's column names\r\n",
							"df = spark.createDataFrame([\r\n",
							"  (\"Hello World\",),\r\n",
							"  (\"Bonjour tout le monde\",),\r\n",
							"  (\"La carretera estaba atascada. Había mucho tráfico el día de ayer.\",),\r\n",
							"  (\"你好\",),\r\n",
							"  (\"こんにちは\",),\r\n",
							"  (\":) :( :D\",)\r\n",
							"], [\"text\",])\r\n",
							"\r\n",
							"# Run the Text Analytics service with options\r\n",
							"language = (LanguageDetector()\r\n",
							"    .setLinkedService(linked_service_name)\r\n",
							"    .setTextCol(\"text\")\r\n",
							"    .setOutputCol(\"language\")\r\n",
							"    .setErrorCol(\"error\"))\r\n",
							"\r\n",
							"# Show the results of your text query in a table format\r\n",
							"display(language.transform(df))\r\n",
							""
						],
						"outputs": [],
						"execution_count": 58
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Remove special characters"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import regexp_replace\r\n",
							"\r\n",
							"# remove special characters from text column\r\n",
							"df = df.withColumn(\"text\", regexp_replace(df[\"text\"], \"[^a-zA-Z0-9\\\\s]\", \"\"))\r\n",
							"\r\n",
							"df_text = df.select('text')\r\n",
							"\r\n",
							"# show resulting dataframe\r\n",
							"df_text.show()"
						],
						"outputs": [],
						"execution_count": 47
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Write back to SQLPoolTest dbo.NATO_Tweets1 table using Azure AD based authentication"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Write using AAD Auth to internal table\r\n",
							"# Add required imports\r\n",
							"import com.microsoft.spark.sqlanalytics\r\n",
							"from com.microsoft.spark.sqlanalytics.Constants import Constants\r\n",
							"\r\n",
							"# Configure and submit the request to write to Synapse Dedicated SQL Pool\r\n",
							"# Sample below is using AAD-based authentication approach; See further examples to leverage SQL Basic auth.\r\n",
							"(df.write\r\n",
							" # If `Constants.SERVER` is not provided, the `<database_name>` from the three-part table name argument\r\n",
							" # to `synapsesql` method is used to infer the Synapse Dedicated SQL End Point.\r\n",
							" .option(Constants.SERVER, \"pendragon-synapse.sql.azuresynapse.net\")\r\n",
							" # Like-wise, if `Constants.TEMP_FOLDER` is not provided, the connector will use the runtime staging directory config (see section on Configuration Options for details).\r\n",
							" .option(Constants.TEMP_FOLDER, \"abfss://pendragon@pendragon.dfs.core.windows.net/NotebookStaging\")\r\n",
							" # Choose a save mode that is apt for your use case.\r\n",
							" # Options for save modes are \"error\" or \"errorifexists\" (default), \"overwrite\", \"append\", \"ignore\".\r\n",
							" # refer to https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html#save-modes\r\n",
							" .mode(\"overwrite\")\r\n",
							" # Required parameter - Three-part table name to which data will be written\r\n",
							" .synapsesql(\"SQLPoolTest.dbo.NATO_Tweets1\"))"
						],
						"outputs": [],
						"execution_count": 44
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/OpenAI')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPoolTest",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "78fc0f2f-9b10-4a78-a38e-4427ed14eba7"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/57cd2ff8-9306-41d0-9cad-c2052a0a8381/resourceGroups/Spring2023-TeamPendragon/providers/Microsoft.Synapse/workspaces/pendragon-synapse/bigDataPools/SparkPoolTest",
						"name": "SparkPoolTest",
						"type": "Spark",
						"endpoint": "https://pendragon-synapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPoolTest",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.3",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"# Add required imports\r\n",
							"import com.microsoft.spark.sqlanalytics\r\n",
							"from com.microsoft.spark.sqlanalytics.Constants import Constants\r\n",
							"from pyspark.sql.functions import col\r\n",
							"\r\n",
							"# Name of the SQL Dedicated Pool or database where to run the query\r\n",
							"# Database can be specified as a Spark Config or as a Constant - Constants.DATABASE\r\n",
							"spark.conf.set(\"spark.sqlanalyticsconnector.dw.database\", \"SQLPoolTest\")\r\n",
							"\r\n",
							"# Read from a query\r\n",
							"# Query can be provided either as an argument to synapsesql or as a Constant - Constants.QUERY\r\n",
							"df = (spark.read\r\n",
							"                     # Name of the SQL Dedicated Pool or database where to run the query\r\n",
							"                     # Database can be specified as a Spark Config - spark.sqlanalyticsconnector.dw.database or as a Constant - Constants.DATABASE\r\n",
							"                     .option(Constants.DATABASE, \"SQLPoolTest\")\r\n",
							"                     # If `Constants.SERVER` is not provided, the `<database_name>` from the three-part table name argument\r\n",
							"                     # to `synapsesql` method is used to infer the Synapse Dedicated SQL End Point.\r\n",
							"                     .option(Constants.SERVER, \"pendragon-synapse.sql.azuresynapse.net\")\r\n",
							"                     # Defaults to storage path defined in the runtime configurations\r\n",
							"                     .option(Constants.TEMP_FOLDER, \"abfss://pendragon@pendragon.dfs.core.windows.net/NotebookStaging\")\r\n",
							"                     # query from which data will be read\r\n",
							"                     .option(Constants.QUERY, \"select * from dbo.NATO_Tweets1\")\r\n",
							"                     .synapsesql()\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# sort dataframe by date column in ascending order\r\n",
							"sorted_df = df.orderBy(col(\"impression_count\").desc())\r\n",
							"\r\n",
							"# show sorted dataframe\r\n",
							"sorted_df.show()"
						],
						"outputs": [],
						"execution_count": 54
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# select the first 20 records\r\n",
							"first_20 = sorted_df.limit(20)\r\n",
							"first_20.show()"
						],
						"outputs": [],
						"execution_count": 55
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark.sql.functions import collect_list, concat_ws\r\n",
							"\r\n",
							"# concatenate strings in \"text\" column into a single string\r\n",
							"concatenated_string = first_20.agg(concat_ws(\"\", collect_list(\"text\"))).collect()[0][0]\r\n",
							"\r\n",
							"print(concatenated_string)"
						],
						"outputs": [],
						"execution_count": 56
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from pyspark import SparkContext\r\n",
							"sc = SparkContext.getOrCreate()\r\n",
							"\r\n",
							"input_string = concatenated_string\r\n",
							"\r\n",
							"def remove_emoji(text):\r\n",
							"    return text.encode('ascii', 'ignore').decode('ascii')\r\n",
							"result_string = remove_emoji(input_string)\r\n",
							"\r\n",
							"words_rdd = sc.parallelize(result_string.split())\r\n",
							"filtered_words_rdd = words_rdd.filter(lambda word: not word.startswith(\"#\"))\r\n",
							"result_string = \" \".join(filtered_words_rdd.collect())\r\n",
							"\r\n",
							"words_rdd = sc.parallelize(result_string.split())\r\n",
							"filtered_words_rdd = words_rdd.filter(lambda word: not word.startswith(\"@\"))\r\n",
							"result_string = \" \".join(filtered_words_rdd.collect())\r\n",
							"\r\n",
							"words_rdd = sc.parallelize(result_string.split())\r\n",
							"filtered_words_rdd = words_rdd.filter(lambda word: not word.startswith(\"&\"))\r\n",
							"result_string = \" \".join(filtered_words_rdd.collect())\r\n",
							"\r\n",
							"words_rdd = sc.parallelize(result_string.split())\r\n",
							"filtered_words_rdd = words_rdd.filter(lambda word: not word.startswith(\"https\"))\r\n",
							"result_string = \" \".join(filtered_words_rdd.collect())\r\n",
							"\r\n",
							"print(result_string)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 57
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#!pip install openai\r\n",
							"import openai\r\n",
							"\r\n",
							"\r\n",
							"openai.api_type = \"azure\"\r\n",
							"openai.api_base = \"https://querystructureddata.openai.azure.com/\"\r\n",
							"openai.api_version = \"2022-12-01\"\r\n",
							"openai.api_key = \"c607bf2bba454302b492ba369efe54f6\""
						],
						"outputs": [],
						"execution_count": 44
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"p = 'Provide a summary of the text below that captures the main idea. ' + result_string"
						],
						"outputs": [],
						"execution_count": 58
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"p"
						],
						"outputs": [],
						"execution_count": 46
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Note: The openai-python library support for Azure OpenAI is in preview.\r\n",
							"import os\r\n",
							"import openai\r\n",
							"openai.api_type = \"azure\"\r\n",
							"openai.api_base = \"https://querystructureddata.openai.azure.com/\"\r\n",
							"openai.api_version = \"2022-12-01\"\r\n",
							"openai.api_key = \"c607bf2bba454302b492ba369efe54f6\"\r\n",
							"\r\n",
							"# query = input(\"Enter your query in natural language: \")\r\n",
							"\r\n",
							"response = openai.Completion.create(\r\n",
							"  engine=\"SumTest\",\r\n",
							"  prompt = p,\r\n",
							"  temperature=0.3,\r\n",
							"  max_tokens=250,\r\n",
							"  top_p=1,\r\n",
							"  frequency_penalty=0,\r\n",
							"  presence_penalty=0,\r\n",
							"  best_of=1,\r\n",
							"  stop=None)\r\n",
							"\r\n",
							"response"
						],
						"outputs": [],
						"execution_count": 59
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"p = 'Perform key phrase extraction on the following text. ' + result_string"
						],
						"outputs": [],
						"execution_count": 60
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Note: The openai-python library support for Azure OpenAI is in preview.\r\n",
							"import os\r\n",
							"import openai\r\n",
							"openai.api_type = \"azure\"\r\n",
							"openai.api_base = \"https://querystructureddata.openai.azure.com/\"\r\n",
							"openai.api_version = \"2022-12-01\"\r\n",
							"openai.api_key = \"c607bf2bba454302b492ba369efe54f6\"\r\n",
							"\r\n",
							"# query = input(\"Enter your query in natural language: \")\r\n",
							"\r\n",
							"response = openai.Completion.create(\r\n",
							"  engine=\"SumTest\",\r\n",
							"  prompt = p,\r\n",
							"  temperature=0.3,\r\n",
							"  max_tokens=250,\r\n",
							"  top_p=1,\r\n",
							"  frequency_penalty=0,\r\n",
							"  presence_penalty=0,\r\n",
							"  best_of=1,\r\n",
							"  stop=None)\r\n",
							"\r\n",
							"response"
						],
						"outputs": [],
						"execution_count": 61
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"p = 'Perform Named Entity Recognition on the following text. ' + result_string"
						],
						"outputs": [],
						"execution_count": 62
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Note: The openai-python library support for Azure OpenAI is in preview.\r\n",
							"import os\r\n",
							"import openai\r\n",
							"openai.api_type = \"azure\"\r\n",
							"openai.api_base = \"https://querystructureddata.openai.azure.com/\"\r\n",
							"openai.api_version = \"2022-12-01\"\r\n",
							"openai.api_key = \"c607bf2bba454302b492ba369efe54f6\"\r\n",
							"\r\n",
							"# query = input(\"Enter your query in natural language: \")\r\n",
							"\r\n",
							"response = openai.Completion.create(\r\n",
							"  engine=\"SumTest\",\r\n",
							"  prompt = p,\r\n",
							"  temperature=0.3,\r\n",
							"  max_tokens=250,\r\n",
							"  top_p=1,\r\n",
							"  frequency_penalty=0,\r\n",
							"  presence_penalty=0,\r\n",
							"  best_of=1,\r\n",
							"  stop=None)\r\n",
							"\r\n",
							"response"
						],
						"outputs": [],
						"execution_count": 63
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"p = 'What is the overall sentiment of the following text as a percentage. ' + result_string"
						],
						"outputs": [],
						"execution_count": 64
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Note: The openai-python library support for Azure OpenAI is in preview.\r\n",
							"import os\r\n",
							"import openai\r\n",
							"openai.api_type = \"azure\"\r\n",
							"openai.api_base = \"https://querystructureddata.openai.azure.com/\"\r\n",
							"openai.api_version = \"2022-12-01\"\r\n",
							"openai.api_key = \"c607bf2bba454302b492ba369efe54f6\"\r\n",
							"\r\n",
							"# query = input(\"Enter your query in natural language: \")\r\n",
							"\r\n",
							"response = openai.Completion.create(\r\n",
							"  engine=\"SumTest\",\r\n",
							"  prompt = p,\r\n",
							"  temperature=0.3,\r\n",
							"  max_tokens=250,\r\n",
							"  top_p=1,\r\n",
							"  frequency_penalty=0,\r\n",
							"  presence_penalty=0,\r\n",
							"  best_of=1,\r\n",
							"  stop=None)\r\n",
							"\r\n",
							"response"
						],
						"outputs": [],
						"execution_count": 65
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SparkPoolTest')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 0,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.3",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": true,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus2"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQLPoolTest')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus2"
		}
	]
}